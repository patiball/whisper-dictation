#!/usr/bin/env python3
import os
import subprocess
import time
import wave
from datetime import datetime

import numpy as np
import pyaudio


def record_test_audio(duration=10, filename_prefix="test"):
    """Nagraj audio testowe i zapisz je na staÅ‚e"""
    print(f"ðŸŽ¤ Nagrywanie przez {duration} sekund...")
    print("ðŸ“£ NAGRAJ TERAZ PO POLSKU:")
    print(
        "   'Jeden, dwa, trzy, cztery, piÄ™Ä‡. To jest test aplikacji whisper z jÄ™zykiem polskim.'"
    )

    # Odliczanie
    for i in range(3, 0, -1):
        print(f"ðŸ”´ {i}...")
        time.sleep(1)
    print("ðŸŽ¯ NAGRYWAM!")

    # Parametry nagrywania (identyczne z aplikacjÄ…)
    frames_per_buffer = 1024
    sample_rate = 16000

    p = pyaudio.PyAudio()
    stream = p.open(
        format=pyaudio.paInt16,
        channels=1,
        rate=sample_rate,
        frames_per_buffer=frames_per_buffer,
        input=True,
    )

    frames = []
    start_time = time.time()

    # Nagrywaj przez okreÅ›lony czas
    while time.time() - start_time < duration:
        data = stream.read(frames_per_buffer)
        frames.append(data)

        # Pokazuj postÄ™p
        elapsed = time.time() - start_time
        remaining = duration - elapsed
        print(f"\râ° PozostaÅ‚o: {remaining:.1f}s", end="", flush=True)

    print("\nâœ… Nagrywanie zakoÅ„czone!")

    stream.stop_stream()
    stream.close()
    p.terminate()

    # Zapisz plik z timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    audio_file = f"{filename_prefix}_{timestamp}.wav"

    with wave.open(audio_file, "wb") as wav_file:
        wav_file.setnchannels(1)  # mono
        wav_file.setsampwidth(2)  # 16-bit
        wav_file.setframerate(sample_rate)
        wav_file.writeframes(b"".join(frames))

    # SprawdÅº rozmiar i dÅ‚ugoÅ›Ä‡
    file_size = os.path.getsize(audio_file)
    duration_actual = len(b"".join(frames)) / (sample_rate * 2)  # 2 bytes per sample

    print(f"ðŸ“ Zapisano: {audio_file}")
    print(f"ðŸ“Š Rozmiar: {file_size/1024:.1f} KB")
    print(f"â±ï¸  DÅ‚ugoÅ›Ä‡: {duration_actual:.1f}s")

    return audio_file


def test_whisper_performance(audio_file, model_path):
    """Przetestuj wydajnoÅ›Ä‡ whisper.cpp z rÃ³Å¼nymi opcjami"""
    print(f"\nðŸ§ª TESTOWANIE WYDAJNOÅšCI: {audio_file}")
    print(f"ðŸ¤– Model: {model_path}")

    # Test 1: Wykrywanie jÄ™zyka
    print("\n1ï¸âƒ£ TEST WYKRYWANIA JÄ˜ZYKA...")
    detect_cmd = [
        "/opt/homebrew/bin/whisper-cli",
        "-m",
        model_path,
        "-dl",  # Detect language only
        audio_file,
    ]

    start_time = time.time()
    result = subprocess.run(detect_cmd, capture_output=True, text=True)
    detect_time = time.time() - start_time

    print(f"â±ï¸  Czas wykrywania: {detect_time:.2f}s")

    # Parse wykryty jÄ™zyk
    detected_lang = "unknown"
    for line in result.stderr.split("\n"):
        if "auto-detected language:" in line.lower():
            if "auto-detected language:" in line:
                lang_start = line.find("auto-detected language:") + len(
                    "auto-detected language:"
                )
                detected_lang = line[lang_start:].strip().split()[0]
                print(f"ðŸŒ Wykryty jÄ™zyk: {detected_lang}")
                break

    # Test 2: Transkrypcja z wykrytym jÄ™zykiem
    print(f"\n2ï¸âƒ£ TEST TRANSKRYPCJI Z JÄ˜ZYKIEM: {detected_lang}")
    transcribe_cmd = [
        "/opt/homebrew/bin/whisper-cli",
        "-m",
        model_path,
        "-l",
        detected_lang,
        "-nt",  # No timestamps
        "-np",  # No prints for clean output
        audio_file,
    ]

    start_time = time.time()
    result = subprocess.run(transcribe_cmd, capture_output=True, text=True)
    transcribe_time = time.time() - start_time

    print(f"â±ï¸  Czas transkrypcji: {transcribe_time:.2f}s")
    print(f"ðŸ“ Transkrypcja: '{result.stdout.strip()}'")

    # Test 3: SprawdÅº czy uÅ¼ywa GPU
    print(f"\n3ï¸âƒ£ TEST WYKORZYSTANIA GPU...")
    gpu_cmd = [
        "/opt/homebrew/bin/whisper-cli",
        "-m",
        model_path,
        "-l",
        detected_lang,
        "-nt",
        audio_file,
    ]

    start_time = time.time()
    result = subprocess.run(gpu_cmd, capture_output=True, text=True)
    gpu_time = time.time() - start_time

    # SprawdÅº stderr dla informacji o GPU
    gpu_info = []
    for line in result.stderr.split("\n"):
        if any(
            keyword in line.lower() for keyword in ["gpu", "metal", "apple m1", "cuda"]
        ):
            gpu_info.append(line.strip())

    print(f"â±ï¸  Czas z GPU info: {gpu_time:.2f}s")
    print("ðŸ–¥ï¸  Informacje GPU:")
    for info in gpu_info[:5]:  # Pokazuj max 5 linii
        print(f"   {info}")

    # Podsumowanie
    total_time = detect_time + transcribe_time
    print(f"\nðŸ“Š PODSUMOWANIE:")
    print(f"   ðŸ” Wykrywanie: {detect_time:.2f}s")
    print(f"   ðŸ“ Transkrypcja: {transcribe_time:.2f}s")
    print(f"   ðŸ”º ÅÄ…cznie: {total_time:.2f}s")
    print(f"   ðŸŒ JÄ™zyk: {detected_lang}")


def main():
    model_path = "/Users/mprzybyszewski/.whisper-models/ggml-medium.bin"

    print("ðŸŽ¯ ZAAWANSOWANY TEST NAGRYWANIA I TRANSKRYPCJI")
    print("=" * 60)

    # Nagraj audio testowe
    audio_file = record_test_audio(10, "test_polish")

    # Przetestuj wydajnoÅ›Ä‡
    test_whisper_performance(audio_file, model_path)

    print(f"\nðŸ’¾ Plik zachowany: {audio_file}")
    print("ðŸ“– Informacje dodane do README.md")


if __name__ == "__main__":
    main()
