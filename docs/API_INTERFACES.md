# API Interfaces - Whisper Dictation

## Spis treÅ›ci

1. [Wprowadzenie](#wprowadzenie)
2. [Recorder API](#recorder-api)
3. [SpeechTranscriber API](#speechtranscriber-api)
4. [DeviceManager API](#devicemanager-api)
5. [Typy danych i klasy pomocnicze](#typy-danych-i-klasy-pomocnicze)
6. [Kontrakty miÄ™dzy komponentami](#kontrakty-miÄ™dzy-komponentami)
7. [ObsÅ‚uga bÅ‚Ä™dÃ³w](#obsÅ‚uga-bÅ‚Ä™dÃ³w)
8. [PrzykÅ‚ady uÅ¼ycia](#przykÅ‚ady-uÅ¼ycia)
9. [PowiÄ…zane dokumenty](#powiÄ…zane-dokumenty)

---

## Wprowadzenie

Ten dokument opisuje publiczne interfejsy API gÅ‚Ã³wnych moduÅ‚Ã³w aplikacji Whisper Dictation. Zawiera szczegÃ³Å‚owe sygnatury metod, parametry, typy zwracane oraz wzorce obsÅ‚ugi bÅ‚Ä™dÃ³w.

### Cel dokumentu

- Dostarczenie kompletnej referencji API dla wszystkich moduÅ‚Ã³w
- Zdefiniowanie kontraktÃ³w miÄ™dzy komponentami
- Dokumentacja wzorcÃ³w obsÅ‚ugi bÅ‚Ä™dÃ³w
- PrzykÅ‚ady integracji moduÅ‚Ã³w

### Konwencje

- Wszystkie Å›cieÅ¼ki plikÃ³w sÄ… bezwzglÄ™dne lub wzglÄ™dne do katalogu gÅ‚Ã³wnego projektu
- Typy danych zgodne z Python 3.x i NumPy/PyTorch
- BÅ‚Ä™dy sÄ… zgÅ‚aszane jako wyjÄ…tki z opisowymi komunikatami

---

## Recorder API

### Klasa: `Recorder`

**Lokalizacja**: `recorder.py`

**Opis**: ZarzÄ…dza nagrywaniem audio z mikrofonu z obsÅ‚ugÄ… rÃ³Å¼nych trybÃ³w pracy i timestampÃ³w.

### Konstruktor

```mermaid
classDiagram
    class Recorder {
        <<interface>>
        +__init__(transcriber=None)
        +sample_rate: int = 16000
        +channels: int = 1
        +format: paInt16
        +chunk_size: int = 1024
    }
    note for Recorder "Manages audio recording from microphone\nwith support for different modes and timestamps"
```

**Parametry inicjalizacji**:
- `transcriber` (SpeechTranscriber, opcjonalny): Instancja transkrybera do automatycznej transkrypcji

### Metody publiczne

```mermaid
classDiagram
    class Recorder {
        +start_recording_with_timestamp() float
        +stop_recording() Optional~ndarray~
        +record_duration(duration_seconds) ndarray
        +start(language=None)
        +stop()
        +save_recording(audio_data, filename)
        +get_recording_delay() float
    }
    note for Recorder "Public API methods for audio recording\nAll methods handle exceptions gracefully"
```

#### start_recording_with_timestamp()

**Opis**: Rozpoczyna nagrywanie i zwraca precyzyjny timestamp poczÄ…tku. Przydatne do synchronizacji z innymi zdarzeniami.

**Zwraca**: Unix timestamp (float) reprezentujÄ…cy moment rozpoczÄ™cia nagrywania

**WyjÄ…tki**:
- `RuntimeError`: Gdy wystÄ…piÅ‚ bÅ‚Ä…d podczas otwierania strumienia audio

**PrzykÅ‚ad**:
```python
recorder = Recorder()
start_time = recorder.start_recording_with_timestamp()
print(f"Nagrywanie rozpoczÄ™te o: {start_time}")
```

#### stop_recording()

```python
def stop_recording(self) -> Optional[np.ndarray]:
    """
    Zatrzymuje nagrywanie i zwraca dane audio.
    
    Returns:
        numpy.ndarray: Tablica float32 z normalizowanymi danymi audio (zakres -1.0 do 1.0)
        None: JeÅ›li nagrywanie nie byÅ‚o aktywne lub brak danych
    """
```

**Opis**: Zatrzymuje aktywne nagrywanie i konwertuje nagrane dane do formatu numpy array.

**Zwraca**: 
- `numpy.ndarray` (dtype=float32): Znormalizowane dane audio w zakresie [-1.0, 1.0]
- `None`: Gdy nagrywanie nie byÅ‚o aktywne

**Format zwracanych danych**:
- Typ: `numpy.ndarray`
- dtype: `float32`
- Shape: `(n_samples,)` - jednowymiarowa tablica
- Zakres wartoÅ›ci: [-1.0, 1.0]
- CzÄ™stotliwoÅ›Ä‡: 16000 Hz

**PrzykÅ‚ad**:
```python
audio_data = recorder.stop_recording()
if audio_data is not None:
    print(f"Nagrano {len(audio_data)} prÃ³bek ({len(audio_data)/16000:.2f}s)")
```

#### record_duration()

```python
def record_duration(self, duration_seconds: float) -> np.ndarray:
    """
    Nagrywa przez okreÅ›lony czas.
    
    Args:
        duration_seconds (float): Czas nagrywania w sekundach
        
    Returns:
        numpy.ndarray: Nagrane dane audio jako float32 array
        
    Raises:
        RuntimeError: Gdy wystÄ…piÅ‚ bÅ‚Ä…d podczas nagrywania
    """
```

**Opis**: Automatycznie nagrywa przez okreÅ›lony czas i zwraca dane.

**Parametry**:
- `duration_seconds` (float): Czas trwania nagrania w sekundach

**Zwraca**: 
- `numpy.ndarray` (dtype=float32): Nagrane dane audio

**PrzykÅ‚ad**:
```python
# Nagraj 5 sekund
audio = recorder.record_duration(5.0)
print(f"Nagrano {len(audio)/16000:.2f} sekund audio")
```

#### start()

```python
def start(self, language: Optional[str] = None):
    """
    Rozpoczyna nagrywanie w tle (wÄ…tek).
    
    Args:
        language (str, opcjonalny): Kod jÄ™zyka dla transkrypcji (np. 'en', 'pl')
    """
```

**Opis**: Rozpoczyna nagrywanie w osobnym wÄ…tku, umoÅ¼liwiajÄ…c asynchroniczne nagrywanie.

**Parametry**:
- `language` (str, opcjonalny): Kod jÄ™zyka ISO 639-1 dla pÃ³Åºniejszej transkrypcji

**Uwagi**:
- Nagrywanie dziaÅ‚a w tle
- Wymaga wywoÅ‚ania `stop()` do zakoÅ„czenia
- JeÅ›li ustawiono transcriber, automatycznie transkrybuje po zatrzymaniu

**PrzykÅ‚ad**:
```python
recorder.start(language='pl')
time.sleep(5)  # Nagrywa przez 5 sekund
recorder.stop()
```

#### stop()

```python
def stop():
    """
    Zatrzymuje nagrywanie w tle.
    """
```

**Opis**: Zatrzymuje nagrywanie uruchomione przez `start()`.

#### save_recording()

```python
def save_recording(self, audio_data: np.ndarray, filename: str):
    """
    Zapisuje dane audio do pliku WAV.
    
    Args:
        audio_data (numpy.ndarray): Dane audio do zapisania
        filename (str): Nazwa pliku wyjÅ›ciowego (z rozszerzeniem .wav)
    """
```

**Opis**: Eksportuje nagrane audio do pliku WAV.

**Parametry**:
- `audio_data` (np.ndarray): Dane audio (float32 lub int16)
- `filename` (str): ÅšcieÅ¼ka do pliku wyjÅ›ciowego

**Format pliku**:
- Format: WAV
- Kodowanie: PCM 16-bit
- KanaÅ‚y: 1 (mono)
- CzÄ™stotliwoÅ›Ä‡: 16000 Hz

**PrzykÅ‚ad**:
```python
audio = recorder.record_duration(3.0)
recorder.save_recording(audio, "recording.wav")
```

#### get_recording_delay()

```python
def get_recording_delay(self) -> float:
    """
    Mierzy opÃ³Åºnienie miÄ™dzy wywoÅ‚aniem start a faktycznym rozpoczÄ™ciem.
    
    Returns:
        float: Åšrednie opÃ³Åºnienie w sekundach (z 3 prÃ³b)
    """
```

**Opis**: NarzÄ™dzie diagnostyczne do pomiaru latencji inicjalizacji nagrywania.

**Zwraca**: Åšrednie opÃ³Åºnienie w sekundach

**PrzykÅ‚ad**:
```python
delay = recorder.get_recording_delay()
print(f"Åšrednie opÃ³Åºnienie startu: {delay*1000:.2f}ms")
```

### WÅ‚aÅ›ciwoÅ›ci klasy Recorder

- `recording` (bool): Flaga statusu nagrywania
- `audio_data` (list): Bufor z fragmentami audio
- `start_timestamp` (float): Timestamp rozpoczÄ™cia nagrywania
- `sample_rate` (int): CzÄ™stotliwoÅ›Ä‡ prÃ³bkowania (16000 Hz)
- `channels` (int): Liczba kanaÅ‚Ã³w (1 - mono)
- `format` (int): Format audio (paInt16)
- `chunk_size` (int): Rozmiar bufora (1024 prÃ³bek)

### Typy wyjÄ…tkÃ³w

- `RuntimeError`: BÅ‚Ä™dy zwiÄ…zane z uruchomieniem/zatrzymaniem nagrywania
- `Exception`: OgÃ³lne bÅ‚Ä™dy przechwytywane w metodach

---

## SpeechTranscriber API

### Klasa: `SpeechTranscriber`

**Lokalizacja**: `transcriber.py`

**Opis**: ZarzÄ…dza transkrypcjÄ… audio na tekst uÅ¼ywajÄ…c modeli Whisper z optymalizacjÄ… urzÄ…dzeÅ„.

### Konstruktor

```mermaid
classDiagram
    class SpeechTranscriber {
        <<interface>>
        +__init__(model_size="base", device=None, allowed_languages=None)
        +model: Whisper
        +device: str
        +device_manager: EnhancedDeviceManager
        +model_size: str
        +model_state: str
    }
    note for SpeechTranscriber "Manages audio-to-text transcription\nusing Whisper models with device optimization"
```

**Parametry**:
- `model_size` (str): 
  - `'tiny'` - 75MB, najszybszy, najmniej dokÅ‚adny
  - `'base'` - 145MB, dobry balans (domyÅ›lny)
  - `'small'` - 483MB, lepsza dokÅ‚adnoÅ›Ä‡
  - `'medium'` - 1.5GB, bardzo dobra dokÅ‚adnoÅ›Ä‡
  - `'large'` - 3GB, najlepsza dokÅ‚adnoÅ›Ä‡

- `device` (str, opcjonalny): Docelowe urzÄ…dzenie obliczeniowe
  - `'cpu'` - CPU (zawsze dostÄ™pne)
  - `'mps'` - Apple Silicon GPU
  - `'cuda'` - NVIDIA GPU
  - `None` - automatyczna detekcja (zalecane)

- `allowed_languages` (list, opcjonalny): Ograniczenie wykrywanych jÄ™zykÃ³w

**WÅ‚aÅ›ciwoÅ›ci**:
- `model` (whisper.model.Whisper): ZaÅ‚adowany model Whisper
- `device` (str): Aktualnie uÅ¼ywane urzÄ…dzenie
- `device_manager` (EnhancedDeviceManager): MenedÅ¼er optymalizacji urzÄ…dzeÅ„
- `model_size` (str): Rozmiar zaÅ‚adowanego modelu
- `model_state` (str): Identyfikator stanu modelu dla testowania

**PrzykÅ‚ad**:
```python
# Podstawowa inicjalizacja
transcriber = SpeechTranscriber()

# Z okreÅ›lonym modelem i ograniczeniem jÄ™zykÃ³w
transcriber = SpeechTranscriber(
    model_size='small',
    allowed_languages=['en', 'pl']
)
```

### Metody publiczne

```mermaid
classDiagram
    class SpeechTranscriber {
        +transcribe(audio_file_path, language=None) TranscriptionResult
        +transcribe_audio_data(audio_data) TranscriptionResult
        +get_model_state() str
    }
    class SpeechTranscriberStatic {
        <<static>>
        +list_available_models() List~Tuple~
        +check_model_available(model_name) bool
    }
    note for SpeechTranscriber "Main transcription methods\nHandles files and raw audio data"
```

#### transcribe()

**Opis**: GÅ‚Ã³wna metoda transkrypcji z pliku audio.

**Parametry**:
- `audio_file_path` (str): ÅšcieÅ¼ka do pliku audio (obsÅ‚ugiwane formaty: WAV, MP3, M4A, itd.)
- `language` (str, opcjonalny): Kod jÄ™zyka ISO 639-1

**Zwraca**: `TranscriptionResult` z polami:
- `text` (str): Transkrybowany tekst
- `language` (str): Wykryty/uÅ¼yty jÄ™zyk
- `detection_time` (float): Czas detekcji jÄ™zyka (sekundy)
- `transcription_time` (float): Czas transkrypcji (sekundy)

**PrzykÅ‚ad**:
```python
result = transcriber.transcribe("recording.wav", language="pl")
print(f"Tekst: {result.text}")
print(f"JÄ™zyk: {result.language}")
print(f"Czas: {result.transcription_time:.2f}s")
```

#### transcribe_audio_data()

```python
def transcribe_audio_data(self, audio_data: np.ndarray) -> TranscriptionResult:
    """
    Transkrybuje surowe dane audio.
    
    Args:
        audio_data (numpy.ndarray): Dane audio jako numpy array (float32)
        
    Returns:
        TranscriptionResult: Obiekt z tekstem, jÄ™zykiem i czasem transkrypcji
        
    Raises:
        Exception: Gdy transkrypcja nie powiodÅ‚a siÄ™
    """
```

**Opis**: Transkrybuje dane audio bezpoÅ›rednio z pamiÄ™ci (np. z Recordera).

**Parametry**:
- `audio_data` (np.ndarray): 
  - dtype: `float32` (preferowany) lub bÄ™dzie skonwertowany
  - Zakres: [-1.0, 1.0] (znormalizowany)
  - Shape: `(n_samples,)`

**Zwraca**: `TranscriptionResult` z:
- `text` (str): Transkrybowany tekst
- `language` (str): Wykryty jÄ™zyk
- `transcription_time` (float): Czas operacji

**PrzykÅ‚ad**:
```python
# Integracja z Recorder
recorder = Recorder()
audio = recorder.record_duration(5.0)
result = transcriber.transcribe_audio_data(audio)
print(result.text)
```

#### get_model_state()

```python
def get_model_state(self) -> str:
    """
    Zwraca identyfikator stanu modelu.
    
    Returns:
        str: Unikalny identyfikator stanu modelu (dla testowania)
    """
```

**Opis**: Metoda pomocnicza do testowania zmiany stanu modelu.

**Zwraca**: String w formacie: `"{model_size}_{device}_{language}_{timestamp}"`

### Metody statyczne

#### list_available_models()

```python
@staticmethod
def list_available_models() -> List[Tuple[str, str]]:
    """
    Listuje modele dostÄ™pne lokalnie.
    
    Returns:
        List[Tuple[str, str]]: Lista krotek (nazwa_modelu, rozmiar_pliku)
    """
```

**Opis**: Skanuje lokalny cache w poszukiwaniu pobranych modeli Whisper.

**Zwraca**: Lista krotek z nazwÄ… modelu i rozmiarem, np. `[('base', '145MB'), ('small', '483MB')]`

**PrzykÅ‚ad**:
```python
models = SpeechTranscriber.list_available_models()
for name, size in models:
    print(f"Model: {name} ({size})")
```

#### check_model_available()

```python
@staticmethod
def check_model_available(model_name: str) -> bool:
    """
    Sprawdza czy okreÅ›lony model jest dostÄ™pny lokalnie.
    
    Args:
        model_name (str): Nazwa modelu do sprawdzenia
        
    Returns:
        bool: True jeÅ›li model jest dostÄ™pny lokalnie
    """
```

**Opis**: Sprawdza dostÄ™pnoÅ›Ä‡ modelu bez jego Å‚adowania.

**Parametry**:
- `model_name` (str): Nazwa modelu ('tiny', 'base', 'small', 'medium', 'large')

**Zwraca**: `True` jeÅ›li model jest w lokalnym cache

**PrzykÅ‚ad**:
```python
if SpeechTranscriber.check_model_available('base'):
    print("Model 'base' jest dostÄ™pny")
else:
    print("Model 'base' wymaga pobrania")
```

### WÅ‚aÅ›ciwoÅ›ci klasy SpeechTranscriber

- `model` (whisper.model.Whisper): Instancja modelu Whisper
- `model_size` (str): Rozmiar modelu ('tiny', 'base', etc.)
- `device` (str): Aktualnie uÅ¼ywane urzÄ…dzenie
- `device_manager` (EnhancedDeviceManager): MenedÅ¼er urzÄ…dzeÅ„
- `allowed_languages` (list): Lista dozwolonych jÄ™zykÃ³w
- `model_state` (str): Identyfikator stanu modelu

### ObsÅ‚ugiwane formaty audio

- WAV (wszystkie warianty PCM)
- MP3
- M4A
- FLAC
- OGG
- Inne formaty obsÅ‚ugiwane przez FFmpeg

### ObsÅ‚ugiwane jÄ™zyki

Model Whisper obsÅ‚uguje 99 jÄ™zykÃ³w. NajczÄ™Å›ciej uÅ¼ywane:

- `en` - Angielski
- `pl` - Polski
- `es` - HiszpaÅ„ski
- `fr` - Francuski
- `de` - Niemiecki
- `it` - WÅ‚oski
- `ja` - JapoÅ„ski
- `zh` - ChiÅ„ski
- PeÅ‚na lista: https://github.com/openai/whisper

---

## DeviceManager API

### Klasa: `DeviceManager`

**Lokalizacja**: `device_manager.py`

**Opis**: Centralne zarzÄ…dzanie urzÄ…dzeniami obliczeniowymi z inteligentnym fallbackiem dla optymalizacji M1/M2.

### Konstruktor

```python
def __init__(self, enable_logging: bool = True):
    """
    Inicjalizuje menedÅ¼era urzÄ…dzeÅ„.
    
    Args:
        enable_logging (bool): Czy wÅ‚Ä…czyÄ‡ logowanie (domyÅ›lnie True)
    """
```

**Parametry**:
- `enable_logging` (bool): Kontrola szczegÃ³Å‚owoÅ›ci logÃ³w

**Inicjalizacja**:
- Automatyczna detekcja dostÄ™pnych urzÄ…dzeÅ„
- Testowanie podstawowych moÅ¼liwoÅ›ci kaÅ¼dego urzÄ…dzenia
- Budowanie hierarchii preferencji urzÄ…dzeÅ„
- Inicjalizacja historii operacji

**PrzykÅ‚ad**:
```python
device_manager = DeviceManager(enable_logging=True)
```

### Metody publiczne

#### get_device_for_operation()

```python
def get_device_for_operation(self, operation: OperationType, 
                            model_size: Optional[str] = None) -> str:
    """
    Zwraca optymalne urzÄ…dzenie dla typu operacji.
    
    Args:
        operation (OperationType): Typ operacji (MODEL_LOADING, TRANSCRIPTION, BASIC_TENSOR)
        model_size (str, opcjonalny): Rozmiar modelu dla optymalizacji pamiÄ™ci
        
    Returns:
        str: Nazwa urzÄ…dzenia ('cpu', 'mps', 'cuda')
    """
```

**Opis**: Inteligentny wybÃ³r urzÄ…dzenia bazujÄ…cy na historii sukcessÃ³w i moÅ¼liwoÅ›ciach.

**Parametry**:
- `operation` (OperationType): 
  - `OperationType.MODEL_LOADING` - Åadowanie modelu
  - `OperationType.TRANSCRIPTION` - Transkrypcja
  - `OperationType.BASIC_TENSOR` - Podstawowe operacje tensorowe
- `model_size` (str, opcjonalny): Rozmiar modelu dla decyzji o pamiÄ™ci

**Zwraca**: String z nazwÄ… urzÄ…dzenia

**Logika wyboru**:
1. Sprawdza moÅ¼liwoÅ›ci urzÄ…dzenia dla danej operacji
2. Analizuje historiÄ™ ostatnich 5 prÃ³b (wspÃ³Å‚czynnik sukcesu > 80%)
3. Wybiera pierwsze urzÄ…dzenie speÅ‚niajÄ…ce kryteria
4. Fallback do CPU jeÅ›li Å¼adne nie speÅ‚nia

**PrzykÅ‚ad**:
```python
device = device_manager.get_device_for_operation(
    OperationType.MODEL_LOADING, 
    model_size='base'
)
print(f"Åadowanie modelu na: {device}")
```

#### handle_device_error()

```python
def handle_device_error(self, error: Exception, 
                       operation: OperationType,
                       current_device: str) -> str:
    """
    ObsÅ‚uguje bÅ‚Ä…d urzÄ…dzenia i zwraca fallback.
    
    Args:
        error (Exception): WyjÄ…tek ktÃ³ry wystÄ…piÅ‚
        operation (OperationType): Typ operacji ktÃ³ra zawiodÅ‚a
        current_device (str): UrzÄ…dzenie na ktÃ³rym wystÄ…piÅ‚ bÅ‚Ä…d
        
    Returns:
        str: UrzÄ…dzenie fallback do uÅ¼ycia
    """
```

**Opis**: Inteligentna obsÅ‚uga bÅ‚Ä™dÃ³w z automatycznym fallbackiem.

**Parametry**:
- `error` (Exception): Przechwycony wyjÄ…tek
- `operation` (OperationType): Kontekst operacji
- `current_device` (str): UrzÄ…dzenie ktÃ³re zawiodÅ‚o

**Zwraca**: Nazwa urzÄ…dzenia fallback

**FunkcjonalnoÅ›Ä‡**:
- Rejestruje bÅ‚Ä…d w historii
- Wykrywa znane problemy MPS (SparseMPS, aten::empty.memory_format)
- Dezaktywuje problematyczne urzÄ…dzenie dla danej operacji
- Wybiera nastÄ™pne najlepsze urzÄ…dzenie
- Zapewnia ultimate fallback do CPU

**PrzykÅ‚ad**:
```python
try:
    result = model.transcribe(audio, device=device)
except Exception as e:
    fallback = device_manager.handle_device_error(
        e, 
        OperationType.TRANSCRIPTION, 
        device
    )
    print(f"PrzeÅ‚Ä…czam na: {fallback}")
    result = model.transcribe(audio, device=fallback)
```

#### register_operation_success()

```python
def register_operation_success(self, device: str, operation: OperationType):
    """
    Rejestruje sukces operacji dla przyszÅ‚ych decyzji.
    
    Args:
        device (str): UrzÄ…dzenie na ktÃ³rym operacja powiodÅ‚a siÄ™
        operation (OperationType): Typ operacji
    """
```

**Opis**: Buduje historiÄ™ sukcessÃ³w dla inteligentnego wyboru urzÄ…dzeÅ„.

**Parametry**:
- `device` (str): Nazwa urzÄ…dzenia
- `operation` (OperationType): Typ operacji

**Uwagi**:
- Przechowuje ostatnie 10 wynikÃ³w
- UÅ¼ywane do kalkulacji wspÃ³Å‚czynnika sukcesu
- WpÅ‚ywa na przyszÅ‚e wybory urzÄ…dzeÅ„

**PrzykÅ‚ad**:
```python
device = device_manager.get_device_for_operation(OperationType.TRANSCRIPTION)
try:
    result = model.transcribe(audio, device=device)
    device_manager.register_operation_success(device, OperationType.TRANSCRIPTION)
except Exception as e:
    fallback = device_manager.handle_device_error(e, OperationType.TRANSCRIPTION, device)
```

#### should_retry_with_fallback()

```python
def should_retry_with_fallback(self, error: Exception) -> bool:
    """
    OkreÅ›la czy bÅ‚Ä…d wymaga automatycznego fallbacku.
    
    Args:
        error (Exception): WyjÄ…tek do analizy
        
    Returns:
        bool: True jeÅ›li naleÅ¼y automatycznie przeÅ‚Ä…czyÄ‡ urzÄ…dzenie
    """
```

**Opis**: Wykrywa znane problemy wymagajÄ…ce fallbacku.

**Parametry**:
- `error` (Exception): WyjÄ…tek do sprawdzenia

**Zwraca**: `True` jeÅ›li wykryto znany problem MPS

**Wykrywane wzorce**:
- `"sparsemps"` - Problemy ze sparse operations na MPS
- `"aten::empty.memory_format"` - Problemy z alokacjÄ… pamiÄ™ci MPS
- `"mps backend"` - OgÃ³lne bÅ‚Ä™dy backendu MPS
- `"metal performance shaders"` - BÅ‚Ä™dy Metal

**PrzykÅ‚ad**:
```python
try:
    result = operation_on_mps()
except Exception as e:
    if device_manager.should_retry_with_fallback(e):
        print("Wykryto problem z MPS, przeÅ‚Ä…czam na CPU")
        result = operation_on_cpu()
    else:
        raise  # Nieznany bÅ‚Ä…d, propaguj dalej
```

#### get_device_status_report()

```python
def get_device_status_report(self) -> Dict:
    """
    Zwraca raport statusu wszystkich urzÄ…dzeÅ„.
    
    Returns:
        Dict: SÅ‚ownik z informacjami o urzÄ…dzeniach, moÅ¼liwoÅ›ciach i historii
    """
```

**Opis**: NarzÄ™dzie diagnostyczne do debugowania problemÃ³w z urzÄ…dzeniami.

**Zwraca**: SÅ‚ownik z:
- `preferred_devices` (list): Hierarchia preferencji urzÄ…dzeÅ„
- `fallback_device` (str): UrzÄ…dzenie fallback (zwykle 'cpu')
- `capabilities` (dict): MoÅ¼liwoÅ›ci kaÅ¼dego urzÄ…dzenia dla rÃ³Å¼nych operacji
- `operation_history` (dict): Historia sukcessÃ³w/poraÅ¼ek operacji

**Struktura capabilities**:
```python
{
    "device_name_operation": {
        "device": "mps",
        "available": True,
        "tested": True,
        "error": None,
        "performance_score": 1.0
    }
}
```

**PrzykÅ‚ad**:
```python
report = device_manager.get_device_status_report()
print("UrzÄ…dzenia preferencyjne:", report['preferred_devices'])
print("MoÅ¼liwoÅ›ci MPS:", report['capabilities'].get('mps_model'))
```

### Metody prywatne (dla zaawansowanych)

#### _test_basic_operations()

```python
def _test_basic_operations(self, device: str) -> DeviceCapability:
    """
    Testuje podstawowe operacje tensorowe.
    
    Args:
        device (str): UrzÄ…dzenie do przetestowania
        
    Returns:
        DeviceCapability: Wynik testu moÅ¼liwoÅ›ci
    """
```

**Opis**: Wykonuje proste operacje tensorowe do weryfikacji dziaÅ‚ania urzÄ…dzenia.

#### _test_model_loading_capability()

```python
def _test_model_loading_capability(self, device: str) -> DeviceCapability:
    """
    Testuje moÅ¼liwoÅ›Ä‡ Å‚adowania modelu bez pobierania Whisper.
    
    Args:
        device (str): UrzÄ…dzenie do przetestowania
        
    Returns:
        DeviceCapability: Wynik testu
    """
```

**Opis**: Lekki test operacji podobnych do Whisper (konwolucje, linear layers).

### WÅ‚aÅ›ciwoÅ›ci klasy DeviceManager

- `logger` (logging.Logger): Logger dla komunikatÃ³w
- `capabilities` (Dict[str, DeviceCapability]): Cache moÅ¼liwoÅ›ci urzÄ…dzeÅ„
- `operation_history` (Dict): Historia sukcessÃ³w/poraÅ¼ek operacji
- `preferred_devices` (List[str]): Hierarchia preferencji urzÄ…dzeÅ„
- `fallback_device` (str): UrzÄ…dzenie fallback (domyÅ›lnie 'cpu')

---

## Typy danych i klasy pomocnicze

### TranscriptionResult

**Lokalizacja**: `transcriber.py`

```python
class TranscriptionResult:
    """Obiekt wyniku transkrypcji z detekcjÄ… jÄ™zyka."""
    
    def __init__(self, text: str, language: str, 
                 detection_time: float = 0, 
                 transcription_time: float = 0):
        self.text = text
        self.language = language
        self.detection_time = detection_time
        self.transcription_time = transcription_time
```

**Pola**:
- `text` (str): Transkrybowany tekst
- `language` (str): Wykryty/uÅ¼yty jÄ™zyk (kod ISO 639-1)
- `detection_time` (float): Czas detekcji jÄ™zyka w sekundach
- `transcription_time` (float): Czas transkrypcji w sekundach

**PrzykÅ‚ad uÅ¼ycia**:
```python
result = transcriber.transcribe("audio.wav")
print(f"Tekst: {result.text}")
print(f"JÄ™zyk: {result.language}")
print(f"Czas caÅ‚kowity: {result.transcription_time:.2f}s")
```

### DeviceCapability

**Lokalizacja**: `device_manager.py`

```python
class DeviceCapability:
    """Wynik oceny moÅ¼liwoÅ›ci urzÄ…dzenia."""
    
    def __init__(self, device: str, available: bool, 
                 tested: bool = False,
                 error: Optional[str] = None, 
                 performance_score: float = 0.0):
        self.device = device
        self.available = available
        self.tested = tested
        self.error = error
        self.performance_score = performance_score
        self.last_test_time = time.time()
```

**Pola**:
- `device` (str): Nazwa urzÄ…dzenia
- `available` (bool): Czy urzÄ…dzenie jest dostÄ™pne dla operacji
- `tested` (bool): Czy urzÄ…dzenie zostaÅ‚o przetestowane
- `error` (Optional[str]): Komunikat bÅ‚Ä™du jeÅ›li test nie powiÃ³dÅ‚ siÄ™
- `performance_score` (float): Ocena wydajnoÅ›ci (0.0 - 1.0)
- `last_test_time` (float): Timestamp ostatniego testu

### OperationType (Enum)

**Lokalizacja**: `device_manager.py`

```python
class OperationType(Enum):
    """Typy operacji wymagajÄ…cych rÃ³Å¼nych urzÄ…dzeÅ„."""
    MODEL_LOADING = "model_loading"
    TRANSCRIPTION = "transcription"
    BASIC_TENSOR = "basic_tensor"
```

**WartoÅ›ci**:
- `MODEL_LOADING`: Åadowanie modelu do pamiÄ™ci
- `TRANSCRIPTION`: Wykonywanie transkrypcji audio
- `BASIC_TENSOR`: Podstawowe operacje tensorowe

### DeviceType (Enum)

**Lokalizacja**: `device_manager.py`

```python
class DeviceType(Enum):
    """ObsÅ‚ugiwane typy urzÄ…dzeÅ„."""
    CPU = "cpu"
    MPS = "mps"
    CUDA = "cuda"
```

**WartoÅ›ci**:
- `CPU`: Procesor (zawsze dostÄ™pny)
- `MPS`: Apple Silicon GPU (Metal Performance Shaders)
- `CUDA`: NVIDIA GPU

---

## Kontrakty miÄ™dzy komponentami

### Recorder â†’ Transcriber

**Format danych**: `numpy.ndarray`

**Specyfikacja**:
- dtype: `float32`
- Shape: `(n_samples,)`
- Zakres wartoÅ›ci: [-1.0, 1.0] (znormalizowane)
- CzÄ™stotliwoÅ›Ä‡: 16000 Hz
- KanaÅ‚y: 1 (mono)

**PrzykÅ‚ad przepÅ‚ywu**:
```python
# Recorder tworzy dane
recorder = Recorder()
audio_data = recorder.record_duration(5.0)
# dtype: float32, shape: (80000,), range: [-1.0, 1.0]

# Transcriber przetwarza dane
transcriber = SpeechTranscriber()
result = transcriber.transcribe_audio_data(audio_data)
# result.text: str
```

### Transcriber â†’ Clipboard/Output

**Format danych**: `str` (UTF-8)

**Specyfikacja**:
- Kodowanie: UTF-8
- Znaki koÅ„ca linii: UsuniÄ™te (`.strip()`)
- Format: Czysty tekst bez formatowania

**PrzykÅ‚ad**:
```python
result = transcriber.transcribe("audio.wav")
text = result.text  # UTF-8 string, stripped
# Gotowe do wklejenia do schowka lub dalszego przetwarzania
```

### DeviceManager â†’ Transcriber

**Format danych**: `torch.device` lub `str`

**Specyfikacja**:
- Typ: String ('cpu', 'mps', 'cuda')
- UÅ¼ywany przez PyTorch/Whisper do alokacji tensora

**PrzykÅ‚ad przepÅ‚ywu**:
```python
# DeviceManager wybiera optymalne urzÄ…dzenie
device_manager = DeviceManager()
device = device_manager.get_device_for_operation(
    OperationType.MODEL_LOADING, 
    model_size='base'
)
# device: 'mps'

# Transcriber uÅ¼ywa wybranego urzÄ…dzenia
transcriber = SpeechTranscriber(model_size='base', device=device)
# Model zaÅ‚adowany na 'mps'
```

### PeÅ‚ny przepÅ‚yw integracji

```python
# 1. Inicjalizacja komponentÃ³w
device_manager = DeviceManager()
device = device_manager.get_device_for_operation(OperationType.MODEL_LOADING)
transcriber = SpeechTranscriber(model_size='base', device=device)
recorder = Recorder(transcriber=transcriber)

# 2. Nagrywanie
audio_data = recorder.record_duration(5.0)
# audio_data: numpy.ndarray, float32, (80000,), [-1.0, 1.0]

# 3. Transkrypcja
transcription_device = device_manager.get_device_for_operation(
    OperationType.TRANSCRIPTION
)
result = transcriber.transcribe_audio_data(audio_data)
# result.text: str (UTF-8)

# 4. Rejestracja sukcesu
device_manager.register_operation_success(
    transcription_device, 
    OperationType.TRANSCRIPTION
)

# 5. Output
print(f"Transkrypcja: {result.text}")
# Gotowe do uÅ¼ycia
```

---

## ObsÅ‚uga bÅ‚Ä™dÃ³w

### Hierarchia wyjÄ…tkÃ³w

```
Exception
â”œâ”€â”€ RuntimeError (Recorder)
â”‚   â””â”€â”€ "Failed to start recording: {details}"
â”œâ”€â”€ FileNotFoundError (Transcriber)
â”‚   â”œâ”€â”€ "Audio file not found: {path}"
â”‚   â””â”€â”€ "Model {size} not available locally and download refused"
â””â”€â”€ Exception (ogÃ³lne)
    â”œâ”€â”€ Problemy z urzÄ…dzeniami (MPS, CUDA)
    â””â”€â”€ BÅ‚Ä™dy transkrypcji
```

### Wzorce obsÅ‚ugi bÅ‚Ä™dÃ³w

#### Recorder - Start recording

```python
try:
    start_time = recorder.start_recording_with_timestamp()
except RuntimeError as e:
    print(f"Nie udaÅ‚o siÄ™ rozpoczÄ…Ä‡ nagrywania: {e}")
    # Fallback: sprawdÅº mikrofon, uprawnienia
```

#### Transcriber - Model loading

```python
try:
    transcriber = SpeechTranscriber(model_size='base')
except FileNotFoundError as e:
    print(f"Model niedostÄ™pny: {e}")
    # Fallback: pobierz model lub uÅ¼yj mniejszego
```

#### Transcriber - Transcription with device fallback

```python
device = device_manager.get_device_for_operation(OperationType.TRANSCRIPTION)

try:
    result = transcriber.transcribe(audio_file, language='pl')
    device_manager.register_operation_success(device, OperationType.TRANSCRIPTION)
    
except Exception as e:
    if device_manager.should_retry_with_fallback(e):
        # Automatyczny fallback
        fallback = device_manager.handle_device_error(
            e, OperationType.TRANSCRIPTION, device
        )
        print(f"ğŸ”„ PrzeÅ‚Ä…czam z {device} na {fallback}")
        
        # Retry na nowym urzÄ…dzeniu
        result = transcriber.transcribe(audio_file, language='pl')
        device_manager.register_operation_success(
            fallback, OperationType.TRANSCRIPTION
        )
    else:
        # Nieznany bÅ‚Ä…d, propaguj
        raise
```

### Znane problemy i rozwiÄ…zania

#### Problem: MPS SparseMPS error

**Objaw**:
```
RuntimeError: SparseMPS not supported for operation
```

**RozwiÄ…zanie**:
```python
# DeviceManager automatycznie wykrywa i przeÅ‚Ä…cza na CPU
if device_manager.should_retry_with_fallback(error):
    fallback = device_manager.handle_device_error(
        error, OperationType.TRANSCRIPTION, 'mps'
    )
    # fallback == 'cpu'
```

#### Problem: Insufficient memory for large model

**Objaw**:
```
RuntimeError: MPS backend out of memory
```

**RozwiÄ…zanie**:
```python
try:
    transcriber = SpeechTranscriber(model_size='large', device='mps')
except RuntimeError as e:
    # UÅ¼yj mniejszego modelu lub CPU
    transcriber = SpeechTranscriber(model_size='medium', device='cpu')
```

#### Problem: Microphone not accessible

**Objaw**:
```
RuntimeError: Failed to start recording: [Errno -9999] Unanticipated host error
```

**RozwiÄ…zanie**:
```python
try:
    recorder.start_recording_with_timestamp()
except RuntimeError:
    print("SprawdÅº:")
    print("1. Uprawnienia do mikrofonu w System Preferences")
    print("2. Czy mikrofon jest podÅ‚Ä…czony")
    print("3. Czy inny program nie uÅ¼ywa mikrofonu")
```

---

## PrzykÅ‚ady uÅ¼ycia

### PrzykÅ‚ad 1: Proste nagrywanie i transkrypcja

```python
from recorder import Recorder
from transcriber import SpeechTranscriber

# Setup
transcriber = SpeechTranscriber(model_size='base')
recorder = Recorder()

# Nagraj 5 sekund
print("Nagrywanie...")
audio = recorder.record_duration(5.0)
print(f"Nagrano {len(audio)/16000:.1f}s")

# Transkrybuj
print("Transkrypcja...")
result = transcriber.transcribe_audio_data(audio)
print(f"Tekst: {result.text}")
print(f"JÄ™zyk: {result.language}")
```

### PrzykÅ‚ad 2: Nagrywanie w tle z automatycznÄ… transkrypcjÄ…

```python
from recorder import Recorder
from transcriber import SpeechTranscriber
import time

# Setup z automatycznÄ… transkrypcjÄ…
transcriber = SpeechTranscriber(model_size='base')
recorder = Recorder(transcriber=transcriber)

# Nagraj w tle
print("Rozpoczynam nagrywanie w tle...")
recorder.start(language='pl')

# Kontynuuj inne operacje
time.sleep(5.0)

# Zatrzymaj (transkrypcja automatyczna)
print("ZatrzymujÄ™...")
recorder.stop()
# Tekst wyÅ›wietli siÄ™ automatycznie
```

### PrzykÅ‚ad 3: Optymalizacja urzÄ…dzeÅ„

```python
from device_manager import DeviceManager, OperationType
from transcriber import SpeechTranscriber
from recorder import Recorder

# Inicjalizacja z optymalizacjÄ…
device_manager = DeviceManager()

# Wybierz optymalne urzÄ…dzenie
device = device_manager.get_device_for_operation(
    OperationType.MODEL_LOADING,
    model_size='base'
)
print(f"Åadowanie modelu na: {device}")

# ZaÅ‚aduj z wybranym urzÄ…dzeniem
transcriber = SpeechTranscriber(model_size='base', device=device)

# Nagraj
recorder = Recorder()
audio = recorder.record_duration(5.0)

# Transkrybuj z obsÅ‚ugÄ… bÅ‚Ä™dÃ³w
transcription_device = device_manager.get_device_for_operation(
    OperationType.TRANSCRIPTION
)

try:
    result = transcriber.transcribe_audio_data(audio)
    device_manager.register_operation_success(
        transcription_device,
        OperationType.TRANSCRIPTION
    )
    print(f"Sukces na {transcription_device}: {result.text}")
    
except Exception as e:
    if device_manager.should_retry_with_fallback(e):
        fallback = device_manager.handle_device_error(
            e, OperationType.TRANSCRIPTION, transcription_device
        )
        print(f"Retry na {fallback}")
        result = transcriber.transcribe_audio_data(audio)
        print(f"Sukces: {result.text}")
    else:
        raise
```

### PrzykÅ‚ad 4: Zapisywanie i Å‚adowanie nagraÅ„

```python
from recorder import Recorder
from transcriber import SpeechTranscriber

# Setup
recorder = Recorder()
transcriber = SpeechTranscriber()

# Nagraj i zapisz
print("Nagrywanie...")
audio = recorder.record_duration(5.0)
recorder.save_recording(audio, "recording.wav")
print("Zapisano do recording.wav")

# PÃ³Åºniej: zaÅ‚aduj i transkrybuj
print("Transkrypcja z pliku...")
result = transcriber.transcribe("recording.wav", language="pl")
print(f"Tekst: {result.text}")
print(f"JÄ™zyk: {result.language}")
print(f"Czas: {result.transcription_time:.2f}s")
```

### PrzykÅ‚ad 5: Diagnostyka urzÄ…dzeÅ„

```python
from device_manager import DeviceManager

# Inicjalizacja
device_manager = DeviceManager()

# Raport statusu
report = device_manager.get_device_status_report()

print("=== Raport urzÄ…dzeÅ„ ===")
print(f"Preferencje: {report['preferred_devices']}")
print(f"Fallback: {report['fallback_device']}")

print("\n=== MoÅ¼liwoÅ›ci ===")
for key, cap in report['capabilities'].items():
    status = "âœ…" if cap['available'] else "âŒ"
    print(f"{status} {key}: {cap.get('error', 'OK')}")

print("\n=== Historia operacji ===")
for (device, op), history in report['operation_history'].items():
    successes = sum(history)
    total = len(history)
    rate = (successes / total * 100) if total > 0 else 0
    print(f"{device}/{op}: {successes}/{total} ({rate:.0f}% sukces)")
```

### PrzykÅ‚ad 6: Sprawdzanie dostÄ™pnych modeli

```python
from transcriber import SpeechTranscriber

# Lista lokalnych modeli
print("=== DostÄ™pne modele ===")
models = SpeechTranscriber.list_available_models()

if models:
    for name, size in models:
        print(f"âœ… {name}: {size}")
else:
    print("Brak lokalnych modeli")

# SprawdÅº konkretny model
model_name = 'base'
if SpeechTranscriber.check_model_available(model_name):
    print(f"\nâœ… Model '{model_name}' jest dostÄ™pny lokalnie")
    transcriber = SpeechTranscriber(model_size=model_name)
else:
    print(f"\nâš ï¸  Model '{model_name}' wymaga pobrania")
    # Zostaniesz zapytany o zgodÄ™ przy inicjalizacji
```

### PrzykÅ‚ad 7: Pomiar opÃ³Åºnienia nagrywania

```python
from recorder import Recorder

recorder = Recorder()

# Zmierz opÃ³Åºnienie startu
delay = recorder.get_recording_delay()
print(f"Åšrednie opÃ³Åºnienie startu nagrywania: {delay*1000:.2f}ms")

# UwzglÄ™dnij w synchronizacji
call_time = time.time()
actual_start = recorder.start_recording_with_timestamp()
print(f"WywoÅ‚anie: {call_time}")
print(f"Start: {actual_start}")
print(f"OpÃ³Åºnienie: {(actual_start - call_time)*1000:.2f}ms")
```

---

## PowiÄ…zane dokumenty

- [Architektura](./ARCHITECTURE.md) - OgÃ³lna architektura systemu
- [PrzepÅ‚ywy danych](./DATA_FLOW.md) - SzczegÃ³Å‚owe diagramy przepÅ‚ywu danych
- [ModuÅ‚y](./MODULES.md) - PrzeglÄ…d wszystkich moduÅ‚Ã³w aplikacji
- [Optymalizacja M1/M2](./M1_OPTIMIZATION.md) - Optymalizacje dla Apple Silicon
- [Testy](./TESTING.md) - Strategia testowania i TDD

---

## Wersjonowanie API

### Obecna wersja: 1.0

**Data**: 2025-10-10

**Status**: Stabilne

### Historia zmian

#### v1.0 (2025-10-10)
- Pierwsza stabilna wersja API
- Implementacja DeviceManager z inteligentnym fallbackiem
- TranscriptionResult z metrykami czasowymi
- PeÅ‚na integracja Recorder â†” Transcriber â†” DeviceManager

### KompatybilnoÅ›Ä‡

- Python: 3.8+
- NumPy: 1.20+
- PyTorch: 2.0+
- Whisper: 1.0+
- PyAudio: 0.2.11+

---

## Najlepsze praktyki

### Inicjalizacja komponentÃ³w

```python
# âœ… Dobre - wykorzystanie DeviceManager
device_manager = DeviceManager()
device = device_manager.get_device_for_operation(OperationType.MODEL_LOADING)
transcriber = SpeechTranscriber(model_size='base', device=device)

# âŒ ZÅ‚e - rÄ™czne ustawianie bez fallbacku
transcriber = SpeechTranscriber(model_size='base', device='mps')
# MoÅ¼e zawieÅ›Ä‡ bez obsÅ‚ugi bÅ‚Ä™dÃ³w
```

### ObsÅ‚uga bÅ‚Ä™dÃ³w

```python
# âœ… Dobre - peÅ‚na obsÅ‚uga z fallbackiem
try:
    result = transcriber.transcribe(audio)
    device_manager.register_operation_success(device, operation)
except Exception as e:
    if device_manager.should_retry_with_fallback(e):
        fallback = device_manager.handle_device_error(e, operation, device)
        result = retry_on_fallback(fallback)
    else:
        handle_unknown_error(e)

# âŒ ZÅ‚e - ignorowanie bÅ‚Ä™dÃ³w
try:
    result = transcriber.transcribe(audio)
except:
    pass  # Cicha poraÅ¼ka
```

### ZarzÄ…dzanie zasobami

```python
# âœ… Dobre - cleanup zasobÃ³w
recorder = Recorder()
try:
    audio = recorder.record_duration(5.0)
finally:
    del recorder  # WywoÅ‚uje __del__ i czyÅ›ci PyAudio

# âœ… Dobre - context manager (jeÅ›li dostÄ™pny)
with Recorder() as recorder:
    audio = recorder.record_duration(5.0)
```

### WydajnoÅ›Ä‡

```python
# âœ… Dobre - reuÅ¼ycie instancji
transcriber = SpeechTranscriber(model_size='base')
for audio_file in audio_files:
    result = transcriber.transcribe(audio_file)
    process(result)

# âŒ ZÅ‚e - wielokrotne Å‚adowanie modelu
for audio_file in audio_files:
    transcriber = SpeechTranscriber(model_size='base')  # Kosztowne!
    result = transcriber.transcribe(audio_file)
```

---

*Dokument wygenerowany: 2025-10-10*
*Wersja API: 1.0*
*Projekt: Whisper Dictation*
