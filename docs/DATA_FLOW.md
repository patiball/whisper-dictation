# DATA_FLOW.md - Przep≈Çyw Danych w Aplikacji Whisper Dictation

## 1. Wprowadzenie

Ten dokument opisuje szczeg√≥≈Çowo przep≈Çywy danych w aplikacji Whisper Dictation - od momentu naci≈õniƒôcia skr√≥tu klawiszowego przez u≈ºytkownika, a≈º do wklejenia transkrybowanego tekstu do aktywnej aplikacji.

### 1.1. G≈Ç√≥wne komponenty

- **GlobalKeyListener / DoubleCommandKeyListener** - nas≈Çuchiwanie skr√≥t√≥w klawiszowych
- **StatusBarApp** - interfejs u≈ºytkownika w pasku menu macOS (rumps)
- **Recorder** - modu≈Ç nagrywania audio przez PyAudio
- **SpeechTranscriber** - modu≈Ç transkrypcji wykorzystujƒÖcy OpenAI Whisper
- **DeviceManager / EnhancedDeviceManager** - zarzƒÖdzanie urzƒÖdzeniami (CPU/MPS/CUDA)
- **SoundPlayer** - odtwarzanie d≈∫wiƒôk√≥w systemowych (Tink.aiff, Pop.aiff)

### 1.2. Formaty danych w systemie

| Typ danych          | Format      | Opis                                      |
|---------------------|-------------|-------------------------------------------|
| **Audio surowe**    | `bytes`     | Dane z mikrofonu, 16-bit PCM, mono, 16kHz |
| **Audio przetworzone** | `np.float32` | Znormalizowane: warto≈õci w zakresie [-1.0, 1.0] |
| **Transkrypcja**    | `str` (UTF-8) | Wynik z modelu Whisper                    |
| **Konfiguracja**    | `dict`      | Opcje transkrypcji (jƒôzyk, model, pr√≥g, FP16) |
| **Stan urzƒÖdzenia** | `str`       | "cpu", "mps", lub "cuda"                |

---

## 2. G≈Ç√≥wny Przep≈Çyw - Happy Path

### 2.1. PrzeglƒÖd kroku po kroku

1. **Inicjalizacja aplikacji**
   - ≈Åadowanie modelu Whisper (tiny/base/small/medium/large)
   - Wyb√≥r optymalnego urzƒÖdzenia (CPU/MPS/CUDA) przez DeviceManager
   - Optymalizacja modelu dla wybranego urzƒÖdzenia
   - Rejestracja listenera klawiatury

2. **U≈ºytkownik naciska skr√≥t klawiszowy**
   - Domy≈õlnie: `Cmd+Option` (macOS) lub `Ctrl+Alt` (inne)
   - Alternatywnie: podw√≥jne naci≈õniƒôcie `Right Command` (--k_double_cmd)

3. **Rozpoczƒôcie nagrywania**
   - StatusBarApp wywo≈Çuje `recorder.start(language)`
   - Odtwarzanie d≈∫wiƒôku "Tink.aiff" (start recording)
   - Timer rozpoczyna odliczanie w ikonie paska menu (üî¥)
   - Opcjonalny limit czasu (domy≈õlnie 30s)

4. **Nagrywanie audio**
   - Otwiercie strumienia PyAudio:
     - Format: 16-bit PCM (paInt16)
     - Kana≈Çy: 1 (mono)
     - Czƒôstotliwo≈õƒá: 16000 Hz
     - Bufor: 1024 pr√≥bki na ramkƒô
   - CiƒÖg≈Çe zapisywanie ramek audio do listy `frames[]`

5. **U≈ºytkownik zatrzymuje nagrywanie**
   - Zwolnienie skr√≥tu klawiszowego lub up≈Çyw max_time
   - StatusBarApp wywo≈Çuje `recorder.stop()`

6. **Przetwarzanie audio**
   - Zamkniƒôcie strumienia PyAudio
   - Odtwarzanie d≈∫wiƒôku "Pop.aiff" (stop recording)
   - Konwersja: `bytes` ‚Üí `np.int16` ‚Üí `np.float32` (normalizacja przez 32768.0)

7. **Transkrypcja**
   - Wywo≈Çanie `transcriber.transcribe(audio_data, language)`
   - Detekcja jƒôzyka (je≈õli nie okre≈õlono)
   - Walidacja jƒôzyka wzglƒôdem `allowed_languages` (je≈õli ustawione)
   - Model Whisper przetwarza audio z optymalizacjami:
     - FP16 na MPS/CUDA
     - Progi: `no_speech_threshold=0.6`, `logprob_threshold=-1.0`
     - Obs≈Çuga b≈Çƒôd√≥w z automatycznym fallback (MPS‚ÜíCPU)

8. **Wklejanie tekstu**
   - Iteracja przez ka≈ºdy znak w `result["text"]`
   - Pomijanie pierwszej spacji
   - Symulacja wpisywania przez `pykeyboard.type(element)`
   - Op√≥≈∫nienie 2.5ms miƒôdzy znakami (`time.sleep(0.0025)`)

9. **Powr√≥t do stanu gotowo≈õci**
   - Ikona w pasku menu wraca do "‚èØ"
   - Menu "Start Recording" aktywne ponownie

### 2.2. Schemat przep≈Çywu danych

```mermaid
flowchart TD
    User[üë§ U≈ºytkownik] -->|Naci≈õniƒôcie skr√≥tu<br/>Cmd+Option| KL[KeyboardListener]
    KL -->|on_key_press<br/>toggle| SBA[StatusBarApp<br/>start_app]
    SBA -->|recorder.start<br/>language| REC[Recorder<br/>_record_impl]
    REC -->|PyAudio<br/>stream.read| Sound1[üîä D≈∫wiƒôk: Tink.aiff]
    Sound1 --> AB[(Audio Buffer<br/>frames bytes)]
    AB -->|Zwolnienie skr√≥tu| Sound2[üîä D≈∫wiƒôk: Pop.aiff]
    Sound2 --> CONV[Konwersja Audio<br/>bytes ‚Üí np.float32]
    CONV -->|audio_data_fp32| ST[SpeechTranscriber<br/>transcribe]
    ST -->|model.transcribe<br/>audio, **options| WM[ü§ñ Whisper Model<br/>base/tiny/small]
    WM -->|result text| KO[Keyboard Output<br/>pykeyboard.type]
    KO -->|Symulacja<br/>wpisywania| AA[üíª Aktywna Aplikacja<br/>tekst wklejony]
    
    style User fill:#e1f5ff
    style AB fill:#fff4e1
    style WM fill:#f0e1ff
    style AA fill:#e1ffe1
```

**Kluczowe punkty przep≈Çywu:**
- **Capture**: Nagrywanie audio jako 16-bit PCM przy 16kHz
- **Transform**: Normalizacja do float32 w zakresie [-1.0, 1.0]
- **Process**: Model Whisper przetwarza audio z optymalizacjami (FP16 na MPS/CUDA)
- **Output**: Symulacja wpisywania z op√≥≈∫nieniem 2.5ms miƒôdzy znakami

---

## 2.3. Diagram Sekwencji - Main Flow

**Plik**: [`docs/diagrams/sequence-main-flow.mmd`](./diagrams/sequence-main-flow.mmd)

Diagram przedstawia szczeg√≥≈ÇowƒÖ sekwencjƒô interakcji miƒôdzy komponentami podczas prawid≈Çowego przep≈Çywu (happy path). Zawiera:

- Interakcjƒô u≈ºytkownika z systemem
- Komunikacjƒô miƒôdzy komponentami
- Przep≈Çyw danych audio
- Proces transkrypcji
- Wklejanie tekstu

[Zobacz diagram ‚Üí](./diagrams/sequence-main-flow.mmd)

---

## 3. Obs≈Çuga B≈Çƒôd√≥w

### 4.1. Typy b≈Çƒôd√≥w

#### 4.1.1. B≈Çƒôdy inicjalizacji

| B≈ÇƒÖd                   | Przyczyna                               | Obs≈Çuga                       |
|------------------------|-----------------------------------------|-------------------------------|
| **Model nie za≈Çadowany** | Brak pliku w cache, b≈ÇƒÖd pobierania     | Komunikat + pytanie o pobranie |
| **UrzƒÖdzenie niedostƒôpne** | MPS/CUDA nie dzia≈Ça                     | Automatyczny fallback na CPU  |
| **Brak pamiƒôci**       | Model za du≈ºy dla urzƒÖdzenia            | Fallback + komunikat          |

**Kod obs≈Çugi**: W `whisper-dictation.py` (linie 337-353) zaimplementowano obs≈Çugƒô b≈Çƒôd√≥w inicjalizacji modelu z automatycznym fallbackiem na CPU w przypadku problem√≥w z urzƒÖdzeniem.

#### 4.1.2. B≈Çƒôdy nagrywania

| B≈ÇƒÖd                 | Przyczyna                               | Obs≈Çuga                       |
|----------------------|-----------------------------------------|-------------------------------|
| **Brak mikrofonu**   | Mikrofon od≈ÇƒÖczony/zajƒôty               | PyAudio exception ‚Üí komunikat |
| **Stream overflow**  | Bufor przepe≈Çniony                      | `exception_on_overflow=False` |
| **Brak uprawnie≈Ñ**   | System nie zezwala na dostƒôp            | Komunikat systemowy macOS     |
**Kod obs≈Çugi**: W `recorder.py` (linie 147-152) b≈Çƒôdy nagrywania sƒÖ przechwytywane, a w przypadku przepe≈Çnienia bufora (`exception_on_overflow=False`) nagrywanie jest kontynuowane.

#### 4.1.3. B≈Çƒôdy transkrypcji

| B≈ÇƒÖd                  | Przyczyna                               | Obs≈Çuga                       |
|-----------------------|-----------------------------------------|-------------------------------|
| **OOM (Out of Memory)** | Audio za d≈Çugie dla urzƒÖdzenia          | Fallback CPU + retry          |
| **Timeout**           | Model zawiesi≈Ç siƒô                      | Timeout nie zaimplementowany (TODO) |
| **Invalid audio**     | Pusta/nieprawid≈Çowa pr√≥bka              | Cichy b≈ÇƒÖd (brak wyj≈õcia)     |
| **Language mismatch** | Jƒôzyk poza `allowed_languages`          | Wymuszenie pierwszego z allowed |

**Kod obs≈Çugi detekcji jƒôzyka**: W `whisper-dictation.py` (linie 47-59) zaimplementowano logikƒô nadpisywania wykrytego jƒôzyka, je≈õli nie znajduje siƒô on na li≈õcie `allowed_languages`.

**Kod obs≈Çugi fallback**: W `transcriber.py` (linie 145-169) zaimplementowano mechanizm automatycznego fallbacku urzƒÖdzenia w przypadku b≈Çƒôd√≥w transkrypcji, z mo≈ºliwo≈õciƒÖ ponowienia pr√≥by na innym urzƒÖdzeniu.

#### 4.1.4. B≈Çƒôdy wklejania tekstu

| B≈ÇƒÖd                   | Przyczyna                               | Obs≈Çuga                       |
|------------------------|-----------------------------------------|-------------------------------|
| **Keyboard input blocked** | Brak uprawnie≈Ñ accessibility            | `try-except pass` - cichy b≈ÇƒÖd |
| **Special characters** | Znaki niedostƒôpne na klawiaturze        | `try-except pass`             |

**Kod obs≈Çugi**: W `whisper-dictation.py` (linie 69-73) b≈Çƒôdy wklejania tekstu sƒÖ cicho ignorowane (`try-except pass`), aby nie przerywaƒá dzia≈Çania aplikacji.

### 4.2. Strategia odzyskiwania (Recovery Strategy)

#### 4.2.1. Device Fallback Chain
```
MPS (M1/M2 GPU) ‚Üí CUDA (NVIDIA GPU) ‚Üí CPU
```

**DeviceManager** ≈õledzi:
- Historiƒô b≈Çƒôd√≥w dla ka≈ºdego urzƒÖdzenia
- Licznik sukces√≥w dla operacji (MODEL_LOADING, TRANSCRIPTION)
- Automatyczny wyb√≥r urzƒÖdzenia na podstawie kontekstu

#### 4.2.2. Enhanced Error Messages
DeviceManager dostarcza przyjazne komunikaty po polsku:
- "üîÑ Wykryto problem z MPS. Prze≈ÇƒÖczam na CPU dla stabilno≈õci."
- "‚úÖ Model za≈Çadowany pomy≈õlnie na urzƒÖdzeniu: cpu"

---

## 4. Diagram Sekwencji - Error Handling

**Plik**: [`docs/diagrams/sequence-error-handling.mmd`](./diagrams/sequence-error-handling.mmd)

Diagram przedstawia r√≥≈ºne scenariusze b≈Çƒôd√≥w i ich obs≈Çugƒô:

- Brak mikrofonu
- Model nie za≈Çadowany / OOM
- B≈Çƒôdy urzƒÖdzenia (MPS/CUDA)
- Timeout transkrypcji
- Automatyczny fallback

[Zobacz diagram ‚Üí](./diagrams/sequence-error-handling.mmd)

---

## 5. Formaty Danych - Szczeg√≥≈Çy Techniczne

### 6.1. Audio Pipeline

```mermaid
flowchart TD
    A[Mikrofon] --> B{PyAudio capture}
    B --> C[bytes[] (paInt16, 16kHz, mono)]
    C --> D{np.frombuffer(dtype=np.int16)}
    D --> E[np.ndarray[int16]]
    E --> F{.astype(np.float32) / 32768.0}
    F --> G[np.ndarray[float32] ‚àà [-1.0, 1.0]]
    G --> H{Whisper model}
    H --> I[str (UTF-8)]
```

### 6.2. Konfiguracja transkrypcji

**Konfiguracja transkrypcji**: Opcje transkrypcji obejmujƒÖ `fp16` (half precision na GPU), `language` (jƒôzyk transkrypcji), `task` (zawsze "transcribe"), `no_speech_threshold`, `logprob_threshold` i `compression_ratio_threshold`.

**Optymalizacje dla M1/M2 (MPS)**:
- `fp16=True` - znaczƒÖco przyspiesza inferancjƒô
- `torch.set_grad_enabled(False)` - wy≈ÇƒÖcza gradienty (inferancja only)

### 6.3. Timing Audio

| Parametr          | Warto≈õƒá       | Obliczenie                               |
|-------------------|---------------|------------------------------------------|
| Sample Rate       | 16000 Hz      | Standardowa czƒôstotliwo≈õƒá dla ASR        |
| Chunk Size        | 1024 pr√≥bki   | ~64ms audio na chunk                     |
| Chunk Frequency   | ~15.6 Hz      | 16000 / 1024                             |
| Inter-char Delay  | 2.5ms         | Op√≥≈∫nienie miƒôdzy znakami przy wpisywaniu |
| Typical Recording | 5-10s         | U≈ºytkownik m√≥wi przez 5-10 sekund        |

**Przyk≈Çad**: 5-sekundowe nagranie
- Ramki: `5s √ó 16000 Hz / 1024 = ~78 chunks`
- Rozmiar bufora: `78 √ó 1024 √ó 2 bytes = ~160 KB`
- Po konwersji float32: `~320 KB`

### 6.4. Model Size vs Performance

| Model  | Rozmiar | RAM (CPU) | VRAM (MPS) | Prƒôdko≈õƒá (CPU) | Prƒôdko≈õƒá (MPS) |
|--------|---------|-----------|------------|----------------|----------------|
| tiny   | 75 MB   | ~400 MB   | ~1 GB      | ~0.5x realtime | ~3x realtime   |
| base   | 145 MB  | ~500 MB   | ~1.2 GB    | ~0.3x realtime | ~2x realtime   |
| small  | 483 MB  | ~1 GB     | ~2 GB      | ~0.15x realtime | ~1x realtime   |
| medium | 1.5 GB  | ~2.5 GB   | ~4 GB      | ~0.05x realtime | ~0.5x realtime |
| large  | 3 GB    | ~5 GB     | ~8 GB      | ~0.02x realtime | ~0.3x realtime |

**Uwaga**: Prƒôdko≈õci sƒÖ przybli≈ºone i zale≈ºƒÖ od:
- D≈Çugo≈õci audio
- Jako≈õci nagrania
- Konkretnego sprzƒôtu (M1 vs M2 Pro)
- Obecno≈õci innych proces√≥w

---

## 6. Szczeg√≥≈Çowe Przep≈Çywy Warunkowe

### 7.1. Decyzja o jƒôzyku transkrypcji

```mermaid
flowchart TD
    A[Rozpoczƒôcie transkrypcji] --> B{language jest ustawiony jawnie?}
    B -- No --> C{allowed_languages?}
    B -- Yes --> D[U≈ºyj language w options]
    C -- Yes --> E[Auto-detect jƒôzyk]
    C -- No --> F[Auto-detect (bez ogranicze≈Ñ)]
    E --> G{detected_lang in allowed_languages?}
    F --> G
    G -- No --> H[Override z allowed_languages[0]]
    G -- Yes --> I[U≈ºyj detected language]
    H --> J[Re-transcribe z wybranym jƒôzykiem]
    I --> J
    D --> J
```

### 7.2. Fallback urzƒÖdzenia przy b≈Çƒôdzie

```mermaid
flowchart TD
    A[model.transcribe()] --> B{WystƒÖpi≈Ç Exception?}
    B -- No --> C[Return result]
    B -- Yes --> D{should_retry_with_fallback?}
    D -- No --> E[Rzuƒá b≈ÇƒÖd]
    D -- Yes --> F[Pobierz fallback device (MPS‚ÜíCPU)]
    F --> G[Print user_message "üîÑ Prze≈ÇƒÖczam..."]
    G --> H[model.to(fallback) & optimize_model()]
    H --> I[Retry transcribe z fallback options]
    I --> J[register_success()]
    J --> C
```

---

## 7. Integracje Zewnƒôtrzne

### 8.1. PyAudio ‚Üî System Audio

- **macOS**: CoreAudio backend
- **Uprawnienia**: "Mikrofon" w System Settings ‚Üí Privacy & Security
- **Domy≈õlne urzƒÖdzenie**: U≈ºywa domy≈õlnego mikrofonu z ustawie≈Ñ systemu

### 8.2. Whisper Model ‚Üî Cache

- **Lokalizacja cache**: `~/.cache/whisper/`
- **Pierwsze uruchomienie**: Model pobierany z Hugging Face
- **Kolejne uruchomienia**: ≈Åadowanie z cache (szybsze)

### 8.3. Keyboard Output ‚Üî macOS Accessibility

- **pynput** wymaga uprawnie≈Ñ Accessibility
- **Prompt systemowy**: Pojawia siƒô przy pierwszym uruchomieniu
- **Manualny spos√≥b**: System Settings ‚Üí Privacy & Security ‚Üí Accessibility ‚Üí dodaj Terminal/Warp

### 8.4. D≈∫wiƒôki Systemowe

- **Odtwarzacz**: `afplay` (command-line audio player na macOS)
- **D≈∫wiƒôki**:
  - Start: `/System/Library/Sounds/Tink.aiff`
  - Stop: `/System/Library/Sounds/Pop.aiff`
- **Non-blocking**: Odtwarzanie w osobnym wƒÖtku

---

## 8. Performance Monitoring

### 9.1. Kluczowe metryki

| Metryka                     | Cel     | Typowa Warto≈õƒá |
|-----------------------------|---------|----------------|
| Model load time             | < 5s    | 2-3s (base/MPS) |
| Audio capture latency       | < 100ms | ~64ms (chunk size) |
| Transcription time (5s audio) | < 2s    | 1-1.5s (base/MPS) |
| Character typing speed      | ~400 chars/s | 2.5ms/char     |

### 9.2. TranscriptionResult tracking

**U≈ºycie**: `TranscriptionResult` jest zwracany przez metody transkrypcji i zawiera `text`, `language`, `detection_time` i `transcription_time`.

---

## 9. Stan Aplikacji

### 10.1. StatusBarApp States

```mermaid
stateDiagram-v2
    [*] --> Idle
    Idle --> Recording: start_app()
    Recording --> Processing: stop_app()
    Processing --> Idle: (async transcription)

    state Idle {
        state "Gotowo≈õƒá" as IdleState
        IdleState : Icon: "‚èØ"
        IdleState : Menu: "Start Recording" ‚úì
        IdleState : Menu: "Stop Recording" ‚úó
    }
    state Recording {
        state "Nagrywa" as RecordingState
        RecordingState : Icon: "(MM:SS) üî¥"
        RecordingState : Menu: "Start Recording" ‚úó
        RecordingState : Menu: "Stop Recording" ‚úì
        RecordingState : Timer: max_time countdown
    }
    state Processing {
        state "Transkrypcja" as ProcessingState
        ProcessingState : Icon: "‚èØ" (przej≈õciowo)
        ProcessingState : Print: "Transcribing..."
    }
```

### 10.2. Recorder States

```mermaid
stateDiagram-v2
    [*] --> NotRecording
    NotRecording --> Recording: start()
    Recording --> NotRecording: stop()

    state NotRecording {
        NotRecording : recording = False
    }
    state Recording {
        Recording : recording = True
        Recording : stream.read() in progress
    }
```

---

## 10. Threading Model

### 11.1. G≈Ç√≥wne wƒÖtki

**G≈Ç√≥wne wƒÖtki**: Aplikacja wykorzystuje model wielowƒÖtkowy, gdzie g≈Ç√≥wny wƒÖtek obs≈Çuguje UI (`rumps.App`), a osobne wƒÖtki sƒÖ dedykowane dla `Keyboard Listener`, `Recording` i `Sound Player`. Opcjonalny wƒÖtek `Timer` jest u≈ºywany do auto-stopu nagrywania.

### 11.2. Thread Safety

**Thread Safety**: Wiƒôkszo≈õƒá operacji jest niezale≈ºna. `recording flag` jest prostym booleanem. `PyAudio stream` jest u≈ºywany tylko w wƒÖtku nagrywania. `Model Whisper` jest thread-safe (inferancja read-only).

---

## 11. PowiƒÖzane Dokumenty

- [**Architektura Systemu**](./ARCHITECTURE.md) - struktura komponent√≥w, diagramy warstw
- [**PrzeglƒÖd Projektu**](./PROJECT_OVERVIEW.md) - cel, funkcjonalno≈õci, wymagania
- [**Plan Dokumentacji**](./DOCUMENTATION_PLAN.md) - status dokumentacji
- [**API Interfaces**](./API_INTERFACES.md) *(planowane)* - interfejsy publiczne modu≈Ç√≥w
- [**Diagram g≈Ç√≥wnego przep≈Çywu**](./diagrams/sequence-main-flow.mmd) - sekwencja happy path
- [**Diagram obs≈Çugi b≈Çƒôd√≥w**](./diagrams/sequence-error-handling.mmd) - scenariusze b≈Çƒôd√≥w
- [**Diagram architektury warstw**](./diagrams/architecture-layers.mmd) - warstwy systemu

---

## 12. Changelog

| Data       | Wersja | Autor | Zmiany                               |
|------------|--------|-------|--------------------------------------|
| 2025-10-10 | 1.0    | Agent | Utworzenie dokumentu na podstawie kodu |

---

## 13. TODO / Przysz≈Çe Usprawnienia

### 14.1. Timeout handling
- [ ] Implementacja timeout dla transkrypcji (obecnie brak)
- [ ] Graceful cancel d≈Çugich transkrypcji

### 14.2. Error notifications
- [ ] macOS native notifications dla b≈Çƒôd√≥w krytycznych
- [ ] Logging errors do pliku (obecnie tylko print)

### 14.3. Audio quality
- [ ] Noise reduction pre-processing
- [ ] VAD (Voice Activity Detection) - auto-trim ciszy

### 14.4. Performance
- [ ] Batch processing dla d≈Çugich nagra≈Ñ
- [ ] Streaming transcription (Whisper streaming API)

### 14.5. UX
- [ ] Progress bar dla d≈Çugich transkrypcji
- [ ] Visual feedback podczas detekcji jƒôzyka
- [ ] Configurable keyboard shortcuts w UI

---

## Metadata

**Wersja dokumentu**: 1.1  
**Data utworzenia**: 2025-10-10  
**Ostatnia aktualizacja**: 2025-10-19  
**Autor**: AI Agent  
**Status**: ‚úÖ Uko≈Ñczone  

**Changelog**:
- 2025-10-19: Zrestrukturyzowano sekcje, poprawiono numeracjƒô i formatowanie tabel, dodano diagramy Mermaid.
- 2025-10-10: Utworzenie dokumentu na podstawie kodu.

---

**Koniec dokumentu DATA_FLOW.md**
