# Architektura aplikacji Whisper Dictation

## 1. Wprowadzenie

Whisper Dictation to wielojƒôzyczna aplikacja dyktowania oparta na modelu OpenAI Whisper ASR, zaprojektowana specjalnie dla platformy macOS z optymalizacjƒÖ pod procesory Apple Silicon (M1/M2). Aplikacja dzia≈Ça jako demon systemowy uruchamiany za pomocƒÖ skr√≥t√≥w klawiszowych, zapewniajƒÖc ca≈Çkowicie offline konwersjƒô mowy na tekst bez udostƒôpniania danych u≈ºytkownika.

Architektura systemu zosta≈Ça zaprojektowana z naciskiem na:
- **Modularno≈õƒá** - wyra≈∫ne rozdzielenie odpowiedzialno≈õci miƒôdzy komponenty
- **Wydajno≈õƒá** - inteligentne zarzƒÖdzanie urzƒÖdzeniami (CPU/GPU) dla optymalnej wydajno≈õci
- **Niezawodno≈õƒá** - mechanizmy fallback i obs≈Çuga b≈Çƒôd√≥w specyficznych dla Apple Silicon
- **Prywatno≈õƒá** - ca≈Çkowicie offline przetwarzanie bez wysy≈Çania danych

System wykorzystuje warstwowƒÖ architekturƒô, gdzie ka≈ºda warstwa ma jasno okre≈õlone zadania i zale≈ºno≈õci, co umo≈ºliwia ≈Çatwe testowanie, rozw√≥j i utrzymanie kodu.

## 2. Warstwy systemu

Aplikacja zosta≈Ça zorganizowana w piƒôƒá g≈Ç√≥wnych warstw, z wyra≈∫nym rozdzieleniem odpowiedzialno≈õci:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Warstwa Prezentacji                      ‚îÇ
‚îÇ              (Rumps, StatusBarApp, ikony)                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     Warstwa Kontroli                        ‚îÇ
‚îÇ        (KeyListeners, SoundPlayer, g≈Ç√≥wna pƒôtla)            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Warstwa Biznesowa                        ‚îÇ
‚îÇ     (Recorder, SpeechTranscriber, DeviceManager)            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     Warstwa Danych                          ‚îÇ
‚îÇ         (numpy buffers, model cache, audio data)            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   Warstwa Integracji                        ‚îÇ
‚îÇ      (PyAudio, PyTorch, Whisper, Pynput, macOS APIs)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2.1. Warstwa Prezentacji

**Odpowiedzialno≈õƒá**: Interfejs u≈ºytkownika, wizualna reprezentacja stanu aplikacji

**Komponenty**:
- `StatusBarApp` (rumps.App) - ikona w menu bar z opcjami
- Ikony statusu - reprezentacja wizualna stanu (‚èØ, üî¥, timer)
- Menu kontekstowe - opcje startu/stopu, wyb√≥r jƒôzyka

**Zale≈ºno≈õci**: 
- macOS Menu Bar API (przez rumps)
- System d≈∫wiƒôk√≥w macOS

**Charakterystyka**:
- Minimalistyczny interfejs nie przeszkadzajƒÖcy w pracy
- Dynamiczna aktualizacja tytu≈Çu z timerem nagrywania
- Ikony zmieniajƒÖce siƒô w zale≈ºno≈õci od stanu (idle ‚Üí recording ‚Üí transcribing)

### 2.2. Warstwa Kontroli

**Odpowiedzialno≈õƒá**: ZarzƒÖdzanie cyklem ≈ºycia aplikacji, obs≈Çuga zdarze≈Ñ u≈ºytkownika

**Komponenty**:
- `GlobalKeyListener` - obs≈Çuga kombinacji klawiszy (cmd+alt)
- `DoubleCommandKeyListener` - specjalny tryb dla podw√≥jnego cmd
- `SoundPlayer` - feedback d≈∫wiƒôkowy (rozpoczƒôcie/zako≈Ñczenie nagrywania)
- G≈Ç√≥wna pƒôtla aplikacji w `whisper-dictation.py`

**Zale≈ºno≈õci**: 
- `pynput` - globalne przechwytywanie skr√≥t√≥w klawiszowych
- `afplay` - odtwarzacz d≈∫wiƒôk√≥w systemowych macOS
- `threading` - asynchroniczna obs≈Çuga zdarze≈Ñ

**Charakterystyka**:
- Nie blokujƒÖcy model obs≈Çugi zdarze≈Ñ
- Separacja logiki nagrywania od interfejsu u≈ºytkownika
- Feedback audio wzorowany na systemowym rozpoznawaniu mowy macOS

### 2.3. Warstwa Biznesowa

**Odpowiedzialno≈õƒá**: Kluczowa logika aplikacji - nagrywanie i transkrypcja

**Komponenty**:

#### Recorder
- ZarzƒÖdzanie strumieniem audio przez PyAudio
- Buforowanie danych audio w czasie rzeczywistym
- Konwersja format√≥w audio (int16 ‚Üí float32)
- Wsparcie dla test√≥w TDD (timestamp, duration)

**Kluczowe metody**:
```python
def start_recording_with_timestamp(self) -> float:
    """Rozpoczyna nagrywanie i zwraca dok≈Çadny timestamp"""

def stop_recording(self) -> np.ndarray:
    """Zatrzymuje nagrywanie i zwraca dane audio"""

def record_duration(self, duration_seconds: float) -> np.ndarray:
    """Nagrywa przez okre≈õlony czas (do test√≥w)"""
```

#### SpeechTranscriber
- ZarzƒÖdzanie modelami Whisper (tiny, base, small, medium, large)
- Wykrywanie jƒôzyka z ograniczeniami (allowed_languages)
- Optymalizacja ustawie≈Ñ transkrypcji dla r√≥≈ºnych urzƒÖdze≈Ñ
- Automatyczna konwersja transkrypcji na wpisywany tekst

**Kluczowe metody**:
```python
def transcribe(self, audio_file_path: str, language: str = None) -> TranscriptionResult:
    """Transkrybuje plik audio z detekcjƒÖ jƒôzyka"""

def transcribe_audio_data(self, audio_data: np.ndarray) -> TranscriptionResult:
    """Transkrybuje surowe dane audio (real-time)"""

def get_model_state(self) -> str:
    """Zwraca identyfikator stanu modelu (do test√≥w)"""
```

#### DeviceManager
- Centralne zarzƒÖdzanie urzƒÖdzeniami (CPU, MPS, CUDA)
- Testowanie mo≈ºliwo≈õci urzƒÖdze≈Ñ przy inicjalizacji
- Historia operacji dla inteligentnego wyboru urzƒÖdzenia
- Automatyczny fallback przy b≈Çƒôdach

**Kluczowe metody**:
```python
def get_device_for_operation(self, operation: OperationType, model_size: str = None) -> str:
    """Wybiera optymalne urzƒÖdzenie dla operacji"""

def handle_device_error(self, error: Exception, operation: OperationType, current_device: str) -> str:
    """Obs≈Çuguje b≈ÇƒÖd urzƒÖdzenia i zwraca fallback"""

def register_operation_success(self, device: str, operation: OperationType):
    """Rejestruje udanƒÖ operacjƒô dla przysz≈Çych decyzji"""
```

#### MPSOptimizer & EnhancedDeviceManager
- Specjalistyczna obs≈Çuga b≈Çƒôd√≥w MPS (Apple Silicon)
- Optymalizacja ustawie≈Ñ Whisper dla M1/M2
- Przyjazne u≈ºytkownikowi komunikaty b≈Çƒôd√≥w (po polsku)
- Monitorowanie zu≈ºycia pamiƒôci

**Zale≈ºno≈õci**:
- PyAudio - nagrywanie audio
- PyTorch - framework ML
- Whisper - silnik ASR
- numpy - przetwarzanie danych audio

### 2.4. Warstwa Danych

**Odpowiedzialno≈õƒá**: Przechowywanie i zarzƒÖdzanie danymi

**Komponenty**:
- **Bufory audio** - numpy arrays przechowujƒÖce pr√≥bki audio (float32)
- **Cache modeli** - `~/.cache/whisper/` przechowuje pobrane modele Whisper
- **Historia operacji** - tracking sukcesu/pora≈ºki operacji na urzƒÖdzeniach
- **Capabilities cache** - informacje o mo≈ºliwo≈õciach urzƒÖdze≈Ñ

**Charakterystyka**:
- Brak persystencji danych audio (prywatno≈õƒá)
- Modele cachowane lokalnie po pierwszym pobraniu
- Dynamiczne zarzƒÖdzanie pamiƒôciƒÖ dla r√≥≈ºnych rozmiar√≥w modeli
- Historia operacji w pamiƒôci (nie persystowana)

### 2.5. Warstwa Integracji

**Odpowiedzialno≈õƒá**: Integracja z zewnƒôtrznymi bibliotekami i API systemowymi

**Komponenty**:
- **PyAudio/PortAudio** - interfejs do urzƒÖdze≈Ñ audio
- **PyTorch** - framework ML z backendami (CPU, MPS, CUDA)
- **Whisper API** - silnik rozpoznawania mowy
- **Pynput** - przechwytywanie globalnych skr√≥t√≥w klawiszowych
- **macOS APIs** - menu bar, d≈∫wiƒôki systemowe, dostƒôp do mikrofonu

**Zale≈ºno≈õci systemowe**:
```bash
brew install portaudio llvm  # Wymagane biblioteki systemowe
```

**Uprawnienia systemowe**:
- Dostƒôp do mikrofonu (Privacy Settings)
- Accessibility permissions (globalne skr√≥ty klawiszowe)

## 3. Komponenty g≈Ç√≥wne

### 3.1. WhisperDictation (Main App)

**Plik**: `whisper-dictation.py`

**Odpowiedzialno≈õƒá**: 
- Punkt wej≈õcia aplikacji
- Inicjalizacja wszystkich komponent√≥w
- Parsowanie argument√≥w wiersza polece≈Ñ
- ZarzƒÖdzanie g≈Ç√≥wnƒÖ pƒôtlƒÖ aplikacji

**Kluczowe metody**:
```python
def parse_args() -> argparse.Namespace:
    """Parsuje argumenty CLI (model, jƒôzyk, skr√≥ty)"""

if __name__ == "__main__":
    # Inicjalizacja DeviceManager
    device_manager = EnhancedDeviceManager()
    device = device_manager.get_device_for_operation(OperationType.MODEL_LOADING, args.model_name)
    
    # ≈Åadowanie modelu z fallback
    try:
        model = load_model(model_name, device=device)
        device_manager.optimize_model(model, device)
    except Exception as e:
        # Automatyczny fallback na CPU
        fallback_device = device_manager.handle_device_error_enhanced(...)
        model = load_model(model_name, device=fallback_device)
```

**Zale≈ºno≈õci**:
- `SpeechTranscriber` - silnik transkrypcji
- `Recorder` - modu≈Ç nagrywania
- `StatusBarApp` - interfejs u≈ºytkownika
- `EnhancedDeviceManager` - zarzƒÖdzanie urzƒÖdzeniami
- `GlobalKeyListener` / `DoubleCommandKeyListener` - obs≈Çuga skr√≥t√≥w

**Argumenty CLI**:
- `-m, --model_name` - rozmiar modelu (tiny/base/small/medium/large)
- `-k, --key_combination` - kombinacja klawiszy (np. cmd_l+alt)
- `--k_double_cmd` - tryb podw√≥jnego Command (jak w systemowym dyktowaniu)
- `-l, --language` - wymuszone jƒôzyki (np. "en,pl")
- `--allowed_languages` - ograniczenie detekcji jƒôzyka
- `-t, --max_time` - maksymalny czas nagrywania (domy≈õlnie 30s)

### 3.2. Recorder

**Plik**: `recorder.py`

**Odpowiedzialno≈õƒá**:
- ZarzƒÖdzanie strumieniem audio z mikrofonu
- Buforowanie danych audio w czasie rzeczywistym
- Precyzyjne timestamping (dla test√≥w wydajno≈õci)
- Zapis nagra≈Ñ do plik√≥w WAV (dla test√≥w)

**Kluczowe metody**:
```python
def start_recording_with_timestamp(self) -> float:
    """
    Rozpoczyna nagrywanie i zwraca dok≈Çadny timestamp poczƒÖtku.
    U≈ºywane w testach wydajno≈õci.
    """

def stop_recording(self) -> np.ndarray:
    """
    Zatrzymuje nagrywanie, zamyka strumie≈Ñ audio.
    Zwraca znormalizowane dane audio (float32).
    """

def record_duration(self, duration_seconds: float) -> np.ndarray:
    """
    Nagrywa przez okre≈õlony czas (do test√≥w automatycznych).
    """
```

**Parametry audio**:
```python
self.sample_rate = 16000      # Hz (wymagane przez Whisper)
self.channels = 1             # Mono
self.format = pyaudio.paInt16 # 16-bit audio
self.chunk_size = 1024        # Pr√≥bek na buffer
```

**Zale≈ºno≈õci**:
- `pyaudio` - interfejs do urzƒÖdze≈Ñ audio
- `numpy` - przetwarzanie danych audio
- `wave` - zapis do plik√≥w WAV
- `SpeechTranscriber` - opcjonalny, do automatycznej transkrypcji

**Przep≈Çyw nagrywania**:
1. Inicjalizacja PyAudio interface
2. Otwarcie strumienia audio (16kHz, mono, int16)
3. CiƒÖg≈Çe czytanie chunks do bufora
4. Przy stop: zamkniƒôcie strumienia
5. Konwersja int16 ‚Üí float32 z normalizacjƒÖ

### 3.3. SpeechTranscriber

**Plik**: `transcriber.py`

**Odpowiedzialno≈õƒá**:
- ZarzƒÖdzanie modelami Whisper (≈Çadowanie, cache, prze≈ÇƒÖczanie)
- Transkrypcja audio z automatycznƒÖ detekcjƒÖ jƒôzyka
- Optymalizacja ustawie≈Ñ dla r√≥≈ºnych urzƒÖdze≈Ñ (CPU/MPS)
- Integracja z DeviceManager dla fallback

**Kluczowe metody**:
```python
def __init__(self, model_size: str = "base", device: str = None, allowed_languages: list = None):
    """
    Inicjalizuje transkrybera z:
    - AutomatycznƒÖ detekcjƒÖ urzƒÖdzenia (przez DeviceManager)
    - Pobieraniem modelu z cache lub internetu
    - OptymalizacjƒÖ dla M1/M2
    """

def transcribe(self, audio_file_path: str, language: str = None) -> TranscriptionResult:
    """
    Transkrybuje plik audio:
    - Wykrywa jƒôzyk je≈õli nie podano
    - Stosuje optymalizacje specyficzne dla urzƒÖdzenia
    - Zwraca TranscriptionResult z timing info
    """

def transcribe_audio_data(self, audio_data: np.ndarray) -> TranscriptionResult:
    """
    Transkrybuje surowe dane audio (numpy array):
    - Do u≈ºytku real-time z Recorder
    - Normalizacja danych je≈õli potrzeba
    - Stosuje te same optymalizacje co transcribe()
    """
```

**Struktura wyniku**:
```python
class TranscriptionResult:
    text: str                    # Transkrybowany tekst
    language: str                # Wykryty/u≈ºyty jƒôzyk
    detection_time: float        # Czas detekcji jƒôzyka (s)
    transcription_time: float    # Czas transkrypcji (s)
```

**Zale≈ºno≈õci**:
- `whisper` - silnik ASR OpenAI
- `torch` - PyTorch framework
- `EnhancedDeviceManager` - inteligentne zarzƒÖdzanie urzƒÖdzeniami
- `numpy` - przetwarzanie audio

**Optymalizacje urzƒÖdze≈Ñ**:
- **MPS (M1/M2)**: fp16=True, beam_size=1, pojedynczy pass
- **CPU**: fp16=False, beam_size=5 (dla tiny/base), lepszy context
- **CUDA**: (je≈õli dostƒôpne) podobne do MPS

**Obs≈Çuga b≈Çƒôd√≥w**:
- Automatyczny fallback MPS ‚Üí CPU przy b≈Çƒôdach SparseMPS
- Przyjazne komunikaty b≈Çƒôd√≥w po polsku
- Rejestracja sukcesu/pora≈ºki dla przysz≈Çych decyzji

### 3.4. DeviceManager

**Plik**: `device_manager.py`

**Odpowiedzialno≈õƒá**:
- Centralne zarzƒÖdzanie urzƒÖdzeniami obliczeniowymi
- Testowanie mo≈ºliwo≈õci urzƒÖdze≈Ñ przy starcie
- ≈öledzenie historii operacji (sukces/pora≈ºka)
- Inteligentny wyb√≥r urzƒÖdzenia na podstawie historii

**Kluczowe metody**:
```python
def get_device_for_operation(self, operation: OperationType, model_size: str = None) -> str:
    """
    Wybiera optymalne urzƒÖdzenie:
    - Sprawdza capabilities cache
    - Analizuje historiƒô operacji (last 5 attempts)
    - Wybiera urzƒÖdzenie z >80% success rate
    - Fallback do CPU je≈õli brak dobrych opcji
    """

def handle_device_error(self, error: Exception, operation: OperationType, current_device: str) -> str:
    """
    Obs≈Çuguje b≈ÇƒÖd urzƒÖdzenia:
    - Loguje b≈ÇƒÖd z categorization
    - Rejestruje pora≈ºkƒô w historii
    - Wy≈ÇƒÖcza urzƒÖdzenie dla operacji je≈õli known issue
    - Zwraca nastƒôpne najlepsze urzƒÖdzenie
    """

def register_operation_success(self, device: str, operation: OperationType):
    """
    Rejestruje sukces operacji:
    - Dodaje True do historii
    - Utrzymuje sliding window (last 10 results)
    - Wp≈Çywa na przysz≈Çe decyzje device selection
    """
```

**Typy operacji** (enum):
```python
class OperationType(Enum):
    MODEL_LOADING = "model_loading"     # ≈Åadowanie modeli Whisper
    TRANSCRIPTION = "transcription"     # Wykonywanie transkrypcji
    BASIC_TENSOR = "basic_tensor"       # Podstawowe operacje tensor
```

**Capabilities testing**:
```python
def _test_basic_operations(self, device: str) -> DeviceCapability:
    """Test prostych operacji tensor (matrix add/multiply)"""

def _test_model_loading_capability(self, device: str) -> DeviceCapability:
    """Test operacji podobnych do Whisper (conv1d, linear)"""
```

**Zale≈ºno≈õci**:
- `torch` - detekcja i testowanie urzƒÖdze≈Ñ
- `logging` - szczeg√≥≈Çowe logowanie decyzji

**Device preference order**:
1. MPS (je≈õli Apple Silicon i dostƒôpne)
2. CUDA (je≈õli NVIDIA GPU dostƒôpne)
3. CPU (zawsze dostƒôpne jako fallback)

**Historia operacji**:
```python
operation_history: Dict[Tuple[str, str], List[bool]]
# Przyk≈Çad: {("mps", "model_loading"): [True, True, False, True, True]}
```

### 3.5. MPSOptimizer & EnhancedDeviceManager

**Plik**: `mps_optimizer.py`

**Odpowiedzialno≈õƒá**:
- Specjalistyczna obs≈Çuga b≈Çƒôd√≥w MPS (Apple Silicon)
- Kategoryzacja b≈Çƒôd√≥w MPS (SparseMPS, memory format, OOM)
- Optymalizacja ustawie≈Ñ Whisper dla M1/M2
- Przyjazne u≈ºytkownikowi komunikaty (po polsku)

**Komponenty**:

#### MPSErrorHandler
```python
class MPSErrorType(Enum):
    SPARSE_BACKEND = "sparse_backend"       # SparseMPS errors
    MEMORY_FORMAT = "memory_format"         # aten::empty.memory_format
    OUT_OF_MEMORY = "out_of_memory"         # MPS OOM
    UNSUPPORTED_OP = "unsupported_operation" # Nieobs≈Çugiwana operacja
    UNKNOWN = "unknown"

def categorize_error(self, error: Exception) -> MPSErrorType:
    """Kategoryzuje b≈ÇƒÖd MPS na podstawie pattern matching"""

def get_user_friendly_message(self, error: Exception) -> str:
    """Zwraca przyjazny komunikat po polsku, np:
    'Wykryto problem kompatybilno≈õci z GPU M1. Prze≈ÇƒÖczam na CPU dla stabilno≈õci.'
    """
```

#### MPSOptimizer
```python
def get_optimal_whisper_settings(self, device: str, model_size: str) -> Dict[str, Any]:
    """
    Zwraca optymalne ustawienia Whisper:
    
    MPS (M1/M2):
    - fp16=True (half precision)
    - beam_size=1 (szybsza dekodowanie)
    - condition_on_previous_text=False (mniej pamiƒôci)
    
    CPU:
    - fp16=False (CPU nie korzysta z fp16)
    - beam_size=5 dla tiny/base (lepsza jako≈õƒá)
    - condition_on_previous_text=True (lepszy context)
    """

def optimize_model_for_m1(self, model, device: str) -> None:
    """
    Stosuje optymalizacje M1:
    - Enable MPS fallback dla unsupported ops
    - Ustawia model.eval() (inference mode)
    - Wy≈ÇƒÖcza gradienty (requires_grad=False)
    """
```

#### EnhancedDeviceManager
```python
class EnhancedDeviceManager:
    """
    Wrapper ≈ÇƒÖczƒÖcy DeviceManager + MPSOptimizer + MPSErrorHandler.
    Zapewnia kompletne zarzƒÖdzanie urzƒÖdzeniami z M1 support.
    """
    
    def handle_device_error_enhanced(self, error: Exception, operation, current_device: str) -> Tuple[str, str]:
        """
        Zwraca: (fallback_device, user_friendly_message)
        Przyk≈Çad: ("cpu", "Wykryto problem kompatybilno≈õci z GPU M1. Prze≈ÇƒÖczam na CPU.")
        """
```

**Zale≈ºno≈õci**:
- `DeviceManager` - base device management
- `torch` - MPS backend detection
- `logging` - error tracking
- `psutil` - memory monitoring (CPU)

**Przyk≈Çad u≈ºycia w kodzie**:
```python
device_manager = EnhancedDeviceManager()
device = device_manager.get_device_for_operation(OperationType.MODEL_LOADING, "base")

try:
    model = load_model("base", device=device)
    device_manager.optimize_model(model, device)
except Exception as e:
    fallback_device, user_msg = device_manager.handle_device_error_enhanced(e, OperationType.MODEL_LOADING, device)
    print(f"üîÑ {user_msg}")
    model = load_model("base", device=fallback_device)
```

## 4. Diagram architektury

Szczeg√≥≈Çowy diagram warstw systemu znajduje siƒô w:

**[Diagram warstw architektury](./diagrams/architecture-layers.mmd)**

Diagram przedstawia:
- 5 g≈Ç√≥wnych warstw systemu
- Przep≈Çyw danych miƒôdzy warstwami
- Kluczowe komponenty w ka≈ºdej warstwie
- Zale≈ºno≈õci miƒôdzy komponentami
- Integracje z zewnƒôtrznymi bibliotekami

Aby wy≈õwietliƒá diagram, u≈ºyj narzƒôdzi obs≈ÇugujƒÖcych Mermaid (np. GitHub, VS Code z rozszerzeniem Mermaid, IntelliJ).

## 5. Wzorce projektowe

System wykorzystuje nastƒôpujƒÖce wzorce projektowe, zidentyfikowane w rzeczywistym kodzie:

### 5.1. Singleton (Implicit)

**Gdzie**: `DeviceManager`, `EnhancedDeviceManager`

**Implementacja**: Choƒá nie klasyczny Singleton, te komponenty sƒÖ tworzone raz przy starcie aplikacji i wsp√≥≈Çdzielone przez wszystkie modu≈Çy.

```python
# W whisper-dictation.py
device_manager = EnhancedDeviceManager()  # Jedna instancja
transcriber = SpeechTranscriber(model, allowed_languages, device_manager)
recorder = Recorder(transcriber)
```

**Uzasadnienie**: Centralizacja zarzƒÖdzania urzƒÖdzeniami i historii operacji wymaga pojedynczej instancji.

### 5.2. Strategy

**Gdzie**: `DeviceManager.get_device_for_operation()`

**Implementacja**: Wyb√≥r strategii (CPU/MPS/CUDA) na podstawie typu operacji i historii:

```python
def get_device_for_operation(self, operation: OperationType, model_size: Optional[str] = None) -> str:
    for device in self.preferred_devices:
        # Strategia: wyb√≥r urzƒÖdzenia na podstawie success rate
        if history_key in self.operation_history:
            recent_successes = self.operation_history[history_key][-5:]
            success_rate = sum(recent_successes) / len(recent_successes)
            
            if success_rate > 0.8:
                return device  # Strategia potwierdzona historycznie
```

**Uzasadnienie**: R√≥≈ºne operacje (≈Çadowanie modelu vs transkrypcja) mogƒÖ preferowaƒá r√≥≈ºne urzƒÖdzenia.

### 5.3. Observer (Event-based)

**Gdzie**: `KeyListener` ‚Üí `StatusBarApp` ‚Üí `Recorder`

**Implementacja**: Wzorzec obserwatora przez callbacks:

```python
class GlobalKeyListener:
    def on_key_press(self, key):
        if self.key1_pressed and self.key2_pressed:
            self.app.toggle()  # Powiadomienie app o zdarzeniu

class StatusBarApp:
    def toggle(self):
        if self.started:
            self.stop_app(None)  # Propagacja do Recorder
        else:
            self.start_app(None)
```

**Uzasadnienie**: Lu≈∫ne powiƒÖzanie miƒôdzy warstwƒÖ kontroli a warstwƒÖ biznesowƒÖ.

### 5.4. Factory (Model Loading)

**Gdzie**: ≈Åadowanie modeli Whisper

**Implementacja**: Factory pattern dla r√≥≈ºnych rozmiar√≥w modeli:

```python
# whisper.load_model() dzia≈Ça jako factory
model = load_model(model_name, device=device)  
# Zwraca odpowiedni model: tiny, base, small, medium, large
```

**Uzasadnienie**: Ukrycie z≈Ço≈ºono≈õci tworzenia r√≥≈ºnych wariant√≥w modeli za prostym interfejsem.

### 5.5. Template Method

**Gdzie**: `Recorder.start()` ‚Üí `_record_impl()`

**Implementacja**: Szkielet algorytmu z customizowalnymi krokami:

```python
def _record_impl(self, language):
    # Template method pattern
    self.sound_player.play_start_sound()    # Hook 1
    
    # G≈Ç√≥wny algorytm (niezmienny)
    stream = p.open(...)
    while self.recording:
        data = stream.read(...)
        frames.append(data)
    
    stream.close()
    self.sound_player.play_stop_sound()     # Hook 2
    
    # Przetwarzanie danych (niezmienne)
    audio_data = np.frombuffer(b''.join(frames), dtype=np.int16)
    self.transcriber.transcribe(audio_data, language)  # Hook 3
```

**Uzasadnienie**: Sta≈Çy przep≈Çyw nagrywania z mo≈ºliwo≈õciƒÖ customizacji (d≈∫wiƒôki, transkrypcja).

### 5.6. Adapter

**Gdzie**: `recorder.py` jako adapter miƒôdzy PyAudio a resztƒÖ aplikacji

**Implementacja**: Opakowuje PyAudio API w prosty interfejs:

```python
class Recorder:
    # Adapter pattern: PyAudio API ‚Üí prosty interfejs
    def start_recording_with_timestamp(self) -> float:
        # Ukrywa z≈Ço≈ºono≈õƒá PyAudio
        self.stream = self.audio_interface.open(...)
        return self.start_timestamp
    
    def stop_recording(self) -> np.ndarray:
        # Konwertuje format PyAudio na numpy array
        audio_bytes = b''.join(self.audio_data)
        return np.frombuffer(audio_bytes, dtype=np.int16)
```

**Uzasadnienie**: Izoluje resztƒô kodu od szczeg√≥≈Ç√≥w implementacji PyAudio.

### 5.7. Chain of Responsibility

**Gdzie**: Device fallback chain w `DeviceManager`

**Implementacja**: Pr√≥ba urzƒÖdze≈Ñ w kolejno≈õci do pierwszego sukcesu:

```python
def handle_device_error(self, error, operation, current_device):
    # Chain of Responsibility pattern
    remaining_devices = [d for d in self.preferred_devices if d != current_device]
    
    for device in remaining_devices:  # Pr√≥buj kolejne urzƒÖdzenia
        if self._device_is_capable(device, operation):
            return device  # Pierwsze zdolne urzƒÖdzenie obs≈Çuguje request
    
    return self.fallback_device  # Ostateczny handler (CPU)
```

**Uzasadnienie**: Graceful degradation - je≈õli MPS zawiedzie, pr√≥buj CUDA, potem CPU.

## 6. Kluczowe decyzje architektoniczne

Dokumentacja w formacie ADR-lite dla najwa≈ºniejszych decyzji architektonicznych.

---

### ADR-001: Dwie r√≥wnoleg≈Çe implementacje (Python vs C++)

**Kontekst**: 
- Model OpenAI Whisper w wersji Python dzia≈Ça tylko na CPU z M1/M2 (problem z PyTorch MPS backend)
- Wersja C++ (whisper.cpp) oferuje natywnƒÖ akceleracjƒô GPU M1, ale ma problemy z jako≈õciƒÖ
- U≈ºytkownicy potrzebujƒÖ wyboru miƒôdzy dok≈Çadno≈õciƒÖ a szybko≈õciƒÖ

**Decyzja**: 
Utrzymanie dw√≥ch r√≥wnoleg≈Çych implementacji:
- **whisper-dictation.py** - wersja Python (dok≈Çadna, CPU only)
- **whisper-dictation-fast.py** - wersja C++ (GPU M1, eksperymentalna)

**Alternatywy rozwa≈ºone**:
1. Tylko wersja Python - odrzucone bo brak GPU acceleration
2. Tylko wersja C++ - odrzucone bo problemy z jako≈õciƒÖ
3. Hybrydowa (Python + whisper.cpp bindings) - zbyt z≈Ço≈ºone

**Konsekwencje**:

‚úÖ **Plusy**:
- U≈ºytkownik wybiera trade-off (jako≈õƒá vs szybko≈õƒá)
- Mo≈ºna rozwijaƒá obie implementacje niezale≈ºnie
- Fallback na Python gdy C++ ma problemy
- Eksperymentowanie z whisper.cpp bez ryzyka dla main branch

‚ùå **Minusy**:
- Duplikacja kodu (StatusBarApp, KeyListeners, itp.)
- Dwa razy wiƒôcej maintenance
- Dokumentacja musi opisywaƒá obie wersje
- Potencjalne rozbie≈ºno≈õci w funkcjonalno≈õciach

**Status**: ‚úÖ **Aktywna** (2025-01)

**Notatki**: 
- Python wersja: rekomendowana dla produkcji
- C++ wersja: tylko do test√≥w i eksperyment√≥w
- W przysz≈Ço≈õci: mo≈ºliwe po≈ÇƒÖczenie gdy PyTorch MPS bƒôdzie stabilne

---

### ADR-002: Ca≈Çkowicie offline processing

**Kontekst**:
- Rozpoznawanie mowy wymaga przetwarzania audio u≈ºytkownika
- Wysy≈Çanie audio do cloud (np. Google Speech API) by≈Çoby szybsze i prostsze
- U≈ºytkownicy mogƒÖ dyktowaƒá poufne informacje (has≈Ça, dane osobowe, medyczne)
- Brak zaufania do cloud providers w kontek≈õcie prywatno≈õci

**Decyzja**: 
Wszystkie operacje (nagrywanie, transkrypcja, przetwarzanie) wykonywane lokalnie bez wysy≈Çania danych.

**Alternatywy rozwa≈ºone**:
1. Cloud API (Google/Azure Speech) - odrzucone bo privacy concerns
2. Hybrydowe (lokalne dla kr√≥tkich, cloud dla d≈Çugich) - odrzucone bo niesp√≥jne
3. Opcjonalny cloud (user choice) - odrzucone bo zwiƒôksza attack surface

**Konsekwencje**:

‚úÖ **Plusy**:
- **100% prywatno≈õci** - dane nigdy nie opuszczajƒÖ urzƒÖdzenia
- Dzia≈Ça bez internetu (np. w samolocie, w podr√≥≈ºy)
- Brak koszt√≥w API (Google Speech: $0.006/15s)
- Brak limit√≥w rate-limiting
- Zgodno≈õƒá z GDPR bez effort

‚ùå **Minusy**:
- Wymaga mocnego CPU/GPU lokalnie
- Pobieranie modeli (75MB - 3GB) przy pierwszym u≈ºyciu
- Brak cloud features (np. speaker diarization, advanced NLP)
- Wolniejsze na starszych maszynach vs cloud API

**Status**: ‚úÖ **Aktywna** (niezmienne wymaganie)

**Notatki**: 
- Core value proposition aplikacji
- Marketing: "Your voice never leaves your device"
- Nie bƒôdzie nigdy zmienione (breach of trust)

---

### ADR-003: Dedykowany DeviceManager dla M1/M2

**Kontekst**:
- PyTorch MPS backend ma problemy z kompatybilno≈õciƒÖ (SparseMPS errors)
- OpenAI Whisper przy pr√≥bie u≈ºycia GPU M1 rzuca exception
- U≈ºytkownicy M1/M2 oczekujƒÖ akceleracji GPU (wszak majƒÖ "Neural Engine")
- Manualny fallback w ka≈ºdym miejscu kodu to anti-pattern

**Decyzja**: 
Utworzenie centralnego `DeviceManager` + `MPSOptimizer` do zarzƒÖdzania urzƒÖdzeniami z:
- Automatycznym testowaniem capabilities przy starcie
- HistoriƒÖ sukcesu/pora≈ºki operacji
- Inteligentnym fallback MPS ‚Üí CPU
- Przyjaznym error handling (komunikaty po polsku)

**Alternatywy rozwa≈ºone**:
1. Try-catch w ka≈ºdym miejscu - odrzucone bo boilerplate
2. Tylko CPU (disable MPS ca≈Çkowicie) - odrzucone bo u≈ºytkownicy chcƒÖ GPU
3. PyTorch autograd detect - odrzucone bo nie rozwiƒÖzuje problemu Whisper

**Konsekwencje**:

‚úÖ **Plusy**:
- **Stabilno≈õƒá** - graceful degradation bez crashy
- **Performance** - u≈ºywa GPU gdy mo≈ºliwe, CPU gdy konieczne
- **UX** - przyjazne komunikaty zamiast stack traces
- **Maintainability** - centralna logika device management
- **Testability** - mo≈ºna mockowaƒá DeviceManager w testach
- **Intelligence** - uczy siƒô kt√≥re operacje dzia≈ÇajƒÖ na MPS

‚ùå **Minusy**:
- Dodatkowa warstwa abstrakcji
- Wiƒôcej kodu do maintenance
- Testing capabilities przy starcie dodaje ~2s do launch time
- Zale≈ºno≈õƒá miƒôdzy modu≈Çami (coupling)

**Status**: ‚úÖ **Aktywna** (critical component)

**Implementacja**:
```python
# Przed ADR-003 (z≈Çy kod):
try:
    model = load_model("base", device="mps")
except:
    model = load_model("base", device="cpu")  # Duplikacja wszƒôdzie

# Po ADR-003 (dobry kod):
device_manager = EnhancedDeviceManager()
device = device_manager.get_device_for_operation(OperationType.MODEL_LOADING, "base")
model = load_model("base", device=device)
device_manager.optimize_model(model, device)
```

**Notatki**: 
- RozwiƒÖzuje ~80% problem√≥w M1 users
- W przysz≈Ço≈õci: podobny pattern dla CUDA (NVIDIA)
- Potencja≈Ç do reuse w innych projektach PyTorch na M1

---

### ADR-004: Rumps dla menu bar (zamiast native AppKit)

**Kontekst**:
- Aplikacja potrzebuje ikony w macOS menu bar
- Native AppKit (Objective-C/Swift) da≈Çoby pe≈ÇnƒÖ kontrolƒô
- Python to g≈Ç√≥wny jƒôzyk projektu (nie Swift)
- Trzeba szybko zbudowaƒá MVP

**Decyzja**: 
U≈ºycie biblioteki `rumps` (Ridiculously Uncomplicated macOS Python Statusbar apps) dla menu bar.

**Alternatywy rozwa≈ºone**:
1. PyObjC + AppKit - odrzucone bo zbyt z≈Ço≈ºone
2. Swift app + Python backend - odrzucone bo wymaga bridge
3. Electron app - odrzucone bo overkill (200MB+ bundle)
4. rumps - **wybrane** bo prosty i pythonowy

**Konsekwencje**:

‚úÖ **Plusy**:
- **Szybki rozw√≥j** - menu bar w <100 linii kodu
- **Pythonowy** - nie trzeba uczyƒá siƒô Objective-C
- **Prosty API** - dekoratory @rumps.clicked
- **Lightweight** - ma≈Çe zu≈ºycie pamiƒôci

‚ùå **Minusy**:
- Ograniczone mo≈ºliwo≈õci UI (vs native)
- Zale≈ºno≈õƒá od unmaintained library (ostatni commit 2019)
- Brak advanced features (np. custom views, animations)
- MacOS only (vendor lock-in)

**Status**: ‚úÖ **Aktywna** (dzia≈Ça dobrze dla obecnych potrzeb)

**Notatki**: 
- Je≈õli rumps stanie siƒô problematyczne ‚Üí migrate do PyObjC
- Obecnie: rumps wystarcza (prosty UI, ikona, menu)
- Future: custom view dla visualize waveform during recording?

---

### ADR-005: Threading model (Background recording + UI thread)

**Kontekst**:
- Nagrywanie audio to blocking I/O operation
- macOS menu bar UI musi byƒá responsive
- PyAudio dzia≈Ça w trybie blocking (stream.read())
- Transkrypcja mo≈ºe trwaƒá 5-10s (dla large model)

**Decyzja**: 
Threading model:
- **Main thread** - rumps event loop (UI)
- **Recording thread** - PyAudio stream reading
- **Transcription** - w recording thread (po zako≈Ñczeniu nagrywania)

**Implementacja**:
```python
def start(self, language=None):
    # Nie blokuj UI thread
    thread = threading.Thread(target=self._record_impl, args=(language,))
    thread.start()

def _record_impl(self, language):
    # Ten kod dzia≈Ça w background thread
    while self.recording:
        data = stream.read(frames_per_buffer)  # Blocking OK
        frames.append(data)
    
    # Transkrypcja te≈º w tym samym thread
    self.transcriber.transcribe(audio_data, language)
```

**Alternatywy rozwa≈ºone**:
1. Single-threaded - odrzucone bo UI freeze
2. Multiprocessing - odrzucone bo overkill (IPC overhead)
3. Async/await - odrzucone bo PyAudio nie jest async-friendly
4. Threading - **wybrane** bo balance simplicity/performance

**Konsekwencje**:

‚úÖ **Plusy**:
- UI pozostaje responsive during recording
- Prosty model (jeden thread per recording)
- Thread safety - recorder ma w≈Çasny state
- Cancel possible przez `self.recording = False`

‚ùå **Minusy**:
- Thread creation overhead (~1ms per start)
- Nie mo≈ºna anulowaƒá transkrypcji (once started, must finish)
- Race conditions mo≈ºliwe (ale w praktyce nie wystƒôpujƒÖ)
- GIL limitations (though PyAudio releases GIL for I/O)

**Status**: ‚úÖ **Aktywna** (wystarczajƒÖca dla use case)

**Notatki**: 
- W przysz≈Ço≈õci: asyncio + aiortc dla streaming transcription?
- Obecnie: threading model dzia≈Ça ≈õwietnie
- Thread pool nie potrzebny (max 1 recording at time)

---

## 7. Obszary ryzyka

### 7.1. Performance Bottlenecks

**Ryzyko**: ≈Åadowanie modeli Whisper

**Opis**: 
Pierwsze ≈Çadowanie modelu (szczeg√≥lnie medium/large) mo≈ºe trwaƒá 10-30s:
- Pobieranie z internetu (model large = 3GB)
- Deserializacja PyTorch checkpoint
- Przeniesienie na urzƒÖdzenie (CPU/MPS)

**Mitigation**:
- ‚úÖ Cache modeli w `~/.cache/whisper/` (tylko pierwsze u≈ºycie jest wolne)
- ‚úÖ Prompt u≈ºytkownika przed pobieraniem (informed consent)
- ‚úÖ Lazy loading - model ≈Çadowany dopiero przy pierwszym u≈ºyciu
- üîÑ TODO: Progressbar dla pobierania modelu

**Severity**: ‚ö†Ô∏è **Medium** (tylko first-time user experience)

---

### 7.2. Memory Usage

**Ryzyko**: Du≈ºe modele Whisper zajmujƒÖ du≈ºo RAM

**Opis**:
```
Model Sizes (RAM usage):
- tiny:   ~75MB   - dla prostych przypadk√≥w
- base:   ~145MB  - rekomendowany default
- small:  ~483MB  - dobra jako≈õƒá
- medium: ~1.5GB  - bardzo dobra jako≈õƒá
- large:  ~3GB    - najlepsza jako≈õƒá
```

Na Macbook Air M1 z 8GB RAM, model large + system + Chrome = OOM risk.

**Mitigation**:
- ‚úÖ Default to `base` model (145MB) - good balance
- ‚úÖ Warning w README about memory requirements
- ‚úÖ Graceful OOM handling w DeviceManager
- ‚ö†Ô∏è MISSING: Runtime memory monitoring & warnings

**Severity**: ‚ö†Ô∏è **Medium** (user can choose smaller model)

**Zalecana akcja**:
```python
# TODO: Add memory check before model loading
def check_available_memory(required_mb: int) -> bool:
    import psutil
    available = psutil.virtual_memory().available / (1024**2)
    return available > required_mb * 1.5  # 50% margin
```

---

### 7.3. Thread Safety

**Ryzyko**: Nagrywanie vs transkrypcja w shared state

**Opis**:
Potencjalne race conditions:
```python
# Scenario 1: User starts recording while transcription in progress
recorder.start()  # Thread 1
recorder.start()  # Thread 2 (before Thread 1 finishes)

# Scenario 2: User spams start/stop quickly
app.toggle()  # Start
app.toggle()  # Stop (before recording actually started)
app.toggle()  # Start again
```

**Current protection**:
```python
# StatusBarApp prevents double-start
if self.started:
    return  # Ignore second start
```

**Missing protection**:
- Brak lock w `Recorder.start()` - mo≈ºliwe dwa r√≥wnoczesne nagrywania
- Brak queue dla pending transcriptions

**Mitigation**:
- ‚úÖ UI-level protection w StatusBarApp (sufficient for normal use)
- ‚ö†Ô∏è Brak thread-level lock w Recorder
- ‚ö†Ô∏è Brak queue dla batch transcriptions

**Severity**: üü° **Low-Medium** (wymaga ≈õwiadomego abuse przez u≈ºytkownika)

**Zalecana akcja**:
```python
# TODO: Add threading.Lock in Recorder
class Recorder:
    def __init__(self):
        self._lock = threading.Lock()
    
    def start(self, language=None):
        if not self._lock.acquire(blocking=False):
            print("Recording already in progress")
            return
        # ... recording logic ...
        self._lock.release()
```

---

### 7.4. MPS Compatibility Issues

**Ryzyko**: Nowe wersje PyTorch mogƒÖ zmieniaƒá MPS backend behavior

**Opis**:
Apple MPS backend jest stosunkowo nowy (PyTorch 1.12+) i wciƒÖ≈º ewoluuje:
- SparseMPS b≈Çƒôdy w PyTorch 2.0
- Nowe operacje dodawane stopniowo
- Breaking changes miƒôdzy minor versions

**Current protection**:
- ‚úÖ `DeviceManager` z automatic fallback MPS ‚Üí CPU
- ‚úÖ Capabilities testing przy starcie
- ‚úÖ Historia operacji (learning from failures)

**Missing protection**:
- Brak pinned version PyTorch w `pyproject.toml` - mo≈ºe z≈Çamaƒá siƒô przy update
- Brak version detection (np. PyTorch 2.0 vs 2.1 may behave differently)

**Mitigation**:
- ‚úÖ Graceful fallback obecny
- ‚ö†Ô∏è TODO: Pin PyTorch version lub test against multiple versions
- ‚ö†Ô∏è TODO: Version-specific workarounds

**Severity**: ‚ö†Ô∏è **Medium** (mo≈ºe z≈Çamaƒá working installation przy update)

**Zalecana akcja**:
```toml
# pyproject.toml - TODO: pin versions
[tool.poetry.dependencies]
torch = "^2.1.0,<2.2"  # Explicit range
openai-whisper = "^20231117"  # Pin known-good version
```

---

### 7.5. Audio Device Issues

**Ryzyko**: Brak mikrofonu lub b≈Çƒôdy PyAudio

**Opis**:
Potencjalne problemy:
- Brak dostƒôpu do mikrofonu (permissions not granted)
- Mikrofon u≈ºywany przez innƒÖ aplikacjƒô (Zoom, Teams)
- Bluetooth headset disconnect w trakcie nagrywania
- Nieprawid≈Çowa konfiguracja audio (48kHz device vs 16kHz recording)

**Current handling**:
```python
# Brak graceful error handling w Recorder
stream = p.open(...)  # Mo≈ºe rzuciƒá exception
```

**Missing protection**:
- Brak sprawdzenia uprawnie≈Ñ przed startem
- Brak listy dostƒôpnych mikrofon√≥w
- Brak fallback na default device
- Brak recovery po disconnect

**Mitigation**:
- ‚ö†Ô∏è TODO: Check microphone permissions before recording
- ‚ö†Ô∏è TODO: List available input devices i wyb√≥r default
- ‚ö†Ô∏è TODO: Handle device errors gracefully
- ‚úÖ Exception catching w thread nie crashuje app

**Severity**: üî¥ **High** (czƒôste w production)

**Zalecana akcja**:
```python
# TODO: Add device checking
def check_microphone_available() -> bool:
    p = pyaudio.PyAudio()
    try:
        default_device = p.get_default_input_device_info()
        return default_device is not None
    except OSError:
        return False
    finally:
        p.terminate()
```

---

### 7.6. Disk Space

**Ryzyko**: Brak miejsca na dysku dla modeli

**Opis**:
Models cache w `~/.cache/whisper/`:
- tiny: 75MB
- base: 145MB
- small: 483MB
- medium: 1.5GB
- large: 3GB

Je≈õli u≈ºytkownik ma wszystkie modele: **~5.3GB**

**Current handling**:
- Whisper download bez sprawdzenia dostƒôpnego miejsca
- Mo≈ºe siƒô nie udaƒá w po≈Çowie (partial download)

**Mitigation**:
- ‚úÖ Prompt przed pobieraniem (user awareness)
- ‚ö†Ô∏è Brak sprawdzenia free space
- ‚ö†Ô∏è Brak cleanup old/unused models

**Severity**: üü° **Low** (rzadkie na nowoczesnych Macach z 256GB+ SSD)

**Zalecana akcja**:
```python
# TODO: Add disk space check
import shutil
def check_disk_space(required_mb: int) -> bool:
    stat = shutil.disk_usage(os.path.expanduser("~/.cache"))
    free_mb = stat.free / (1024**2)
    return free_mb > required_mb
```

---

## 8. PowiƒÖzane dokumenty

### Dokumentacja g≈Ç√≥wna

- **[README](../README.md)** - szczeg√≥≈Çowa dokumentacja projektu, instalacja i u≈ºycie
- **[PrzeglƒÖd projektu](./PROJECT_OVERVIEW.md)** - cel aplikacji, stos technologiczny, kluczowe funkcjonalno≈õci

### Diagramy

- **[Diagram warstw](./diagrams/architecture-layers.mmd)** - szczeg√≥≈Çowy diagram 5 warstw systemu
- **[Diagram systemowy](./diagrams/system-overview.mmd)** - overview komponent√≥w i przep≈Çyw√≥w

### Dokumentacja przysz≈Ça (planowana)

- **[Przep≈Çywy danych](./DATA_FLOW.md)** *(planowane)* - szczeg√≥≈Çowe przep≈Çywy: nagrywanie ‚Üí transkrypcja ‚Üí typing
- **[API Reference](./API_REFERENCE.md)** *(planowane)* - dokumentacja publicznych API ka≈ºdego modu≈Çu
- **[Testing Strategy](./TESTING.md)** *(planowane)* - strategie testowania (unit, integration, performance)
- **[Performance Tuning](./PERFORMANCE.md)** *(planowane)* - optymalizacje M1/M2, benchmarks, profiling
- **[Deployment Guide](./DEPLOYMENT.md)** *(planowane)* - packaging, dystrybucja, auto-update

### Kontekst developerski

- **[CURSORRULES](../.cursorrules)** - projekt-specific patterns dla AI agents
- **[Memory Bank](../memory-bank/)** - bank pamiƒôci z kontekstem rozwojowym
- **[Tasks](./tasks/)** - tracking zada≈Ñ i decyzji projektowych

### Zasoby zewnƒôtrzne

- [OpenAI Whisper GitHub](https://github.com/openai/whisper) - oficjalna dokumentacja modelu
- [PyTorch MPS Backend](https://pytorch.org/docs/stable/notes/mps.html) - dokumentacja Apple Silicon support
- [PyAudio Documentation](https://people.csail.mit.edu/hubert/pyaudio/docs/) - API reference
- [Rumps Documentation](https://rumps.readthedocs.io/) - macOS status bar apps

---

## Metadata

**Wersja dokumentu**: 1.0  
**Data utworzenia**: 2025-10-10  
**Ostatnia aktualizacja**: 2025-10-10  
**Autor**: AI Agent (based on codebase analysis)  
**Status**: ‚úÖ Uko≈Ñczone  

**Changelog**:
- 2025-10-10: Initial version - comprehensive architecture documentation based on actual code analysis
